{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations & Configuration"
      ],
      "metadata": {
        "id": "jNgoPgsqdUbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from torch.optim import Adam\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "kaggle_json_path = '/content/drive/MyDrive/ColabNotebooks/A5/kaggle.json'\n",
        "\n",
        "# Copy kaggle.json to the correct location\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp {kaggle_json_path} ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "M4ko-nsGdUM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ],
      "metadata": {
        "id": "hUzTJsWIdMeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the movie posters from kaggle\n",
        "!kaggle datasets download -d rezaunderfit/48k-imdb-movies-with-posters > /dev/null 2>&1\n",
        "!unzip -q 48k-imdb-movies-with-posters.zip\n",
        "\n",
        "# Load title basics\n",
        "tsv_path = '/content/drive/MyDrive/ColabNotebooks/A5/title.basics.tsv'\n",
        "title_basics = pd.read_csv(tsv_path, sep='\\t', na_values='\\\\N')\n",
        "\n",
        "# List all files in the Poster directory\n",
        "poster_dir = 'Poster'\n",
        "poster_files = []\n",
        "for root, _, files in os.walk(poster_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            if os.path.getsize(file_path) > 0:  # Only include non-zero byte files\n",
        "                poster_files.append(file_path)\n",
        "\n",
        "# Extract tconst and startYear from file paths\n",
        "poster_info = []\n",
        "for file_path in poster_files:\n",
        "    parts = file_path.split('/')\n",
        "    start_year = parts[1]\n",
        "    tconst = parts[2]\n",
        "    poster_info.append((start_year, tconst))\n",
        "\n",
        "# Convert to DataFrame\n",
        "poster_df = pd.DataFrame(poster_info, columns=['startYear', 'tconst'])\n",
        "\n",
        "# Ensure startYear is an integer\n",
        "poster_df['startYear'] = poster_df['startYear'].astype(int)\n",
        "title_basics['startYear'] = title_basics['startYear'].astype(float).fillna(0).astype(int)  # Handle missing startYear and convert to int\n",
        "\n",
        "# Merge with title_basics to keep only relevant records\n",
        "title_basics_filtered = pd.merge(title_basics, poster_df, on=['startYear', 'tconst'])\n",
        "\n",
        "# Create your data splits\n",
        "train_metadata, test_metadata = train_test_split(title_basics_filtered, test_size=0.2, random_state=42)\n",
        "train_metadata, val_metadata = train_test_split(train_metadata, test_size=0.25, random_state=42)\n",
        "print(f\"Train size: {len(train_metadata)}, Validation size: {len(val_metadata)}, Test size: {len(test_metadata)}\")\n",
        "\n",
        "# Function to count genres\n",
        "def count_genres(metadata):\n",
        "    genre_counter = Counter()\n",
        "    for genres in metadata['genres'].dropna():\n",
        "        first_genre = genres.split(',')[0]\n",
        "        genre_counter[first_genre] += 1\n",
        "    return genre_counter\n",
        "\n",
        "# Count genres in the training dataset\n",
        "train_genre_counts = count_genres(train_metadata)\n",
        "\n",
        "# Total number of movies in the training dataset\n",
        "total_movies = len(train_metadata)\n",
        "\n",
        "# Calculate and print genre distribution with percentages\n",
        "print(\"\\nGenre Distribution in Training Dataset:\")\n",
        "for genre, count in train_genre_counts.items():\n",
        "    percentage = (count / total_movies) * 100\n",
        "    print(f\"{genre} - {count} ({percentage:.2f}%)\")\n",
        "\n",
        "# Define the image transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, metadata, img_dir, transform=None, genre_to_index=None):\n",
        "        self.metadata = metadata\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.genre_to_index = genre_to_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tconst = self.metadata.iloc[idx]['tconst']\n",
        "        start_year = self.metadata.iloc[idx]['startYear']\n",
        "        img_name = os.path.join(self.img_dir, str(start_year), tconst, f\"{tconst}.jpg\")\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        genres = self.metadata.iloc[idx]['genres']\n",
        "        genre_tensor = self.genres_to_tensor(genres)\n",
        "        return image, genre_tensor\n",
        "\n",
        "    def genres_to_tensor(self, genres):\n",
        "        first_genre = genres.split(',')[0] if pd.notna(genres) else 'Unknown'\n",
        "        genre_index = self.genre_to_index.get(first_genre, self.genre_to_index['Unknown'])\n",
        "        return torch.tensor(genre_index, dtype=torch.long)\n",
        "\n",
        "# Create a mapping from genre to index\n",
        "all_genres = set(g.split(',')[0] for g in title_basics_filtered['genres'].dropna())\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(all_genres)}\n",
        "genre_to_index['Unknown'] = len(genre_to_index)\n",
        "\n",
        "# Directory containing images\n",
        "img_dir = 'Poster'\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MovieDataset(metadata=train_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "val_dataset = MovieDataset(metadata=val_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "test_dataset = MovieDataset(metadata=test_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Example of using the DataLoader\n",
        "for images, genres in train_loader:\n",
        "    print(images.shape)  # Shape: (batch_size, 3, 299, 299)\n",
        "    print(genres.shape)  # Shape: (batch_size,)\n",
        "    break"
      ],
      "metadata": {
        "id": "Un3zXmMXdLi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Tuning via Optuna"
      ],
      "metadata": {
        "id": "qS6gapEHz70v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "def objective(trial):\n",
        "    # hyperparameters values\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Load pretrained model\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "    model.aux_logits = False\n",
        "    num_genres = len(genre_to_index)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_genres)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 5  # Reduced number of epochs for hyperparameter tuning\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 2  # Early stopping patience\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, genres in train_loader:\n",
        "            images = images.to(device)\n",
        "            genres = genres.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, genres)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_genres in val_loader:\n",
        "                val_images = val_images.to(device)\n",
        "                val_genres = val_genres.to(device)\n",
        "                val_outputs = model(val_images)\n",
        "                val_loss += criterion(val_outputs, val_genres).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        trial.report(val_loss, epoch)\n",
        "\n",
        "        # Pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "# Create the study and optimize\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50, timeout=3600)  # Set a timeout to limit the total tuning time\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best hyperparameters: \", study.best_params)"
      ],
      "metadata": {
        "id": "UdpjOnMFz7aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning --> Fine Tuning (Training & Validation)"
      ],
      "metadata": {
        "id": "Gx4aXRhgaA4S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU3JxRHSZ-Rc"
      },
      "outputs": [],
      "source": [
        "# Modify based off of hyper tuning\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "weight_decay = 0.0001\n",
        "\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Set up model for fine tuning\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "model.aux_logits = False  # Disable auxiliary logits\n",
        "num_genres = len(genre_to_index)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_genres)  # Adjust the final layer\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# Training loop with validation\n",
        "num_epochs = 10\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
        "\n",
        "    for images, genres in train_loader_tqdm:\n",
        "        images = images.to(device)\n",
        "        genres = genres.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, genres)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_images, val_genres in val_loader:\n",
        "            val_images = val_images.to(device)\n",
        "            val_genres = val_genres.to(device)\n",
        "            val_outputs = model(val_images)\n",
        "            val_loss += criterion(val_outputs, val_genres).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(train_loader)}, Validation Loss: {val_loss}\")\n",
        "\n",
        "    # Save the model if validation loss decreases\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/ColabNotebooks/A5/best_model_inception.pth')\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning --> Fine Tuning (Testing)"
      ],
      "metadata": {
        "id": "OFkRWZLQYbb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ColabNotebooks/A5/best_model_inception.pth'))\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
        "    for test_images, test_genres in test_loader_tqdm:\n",
        "        test_images = test_images.to(device)\n",
        "        test_genres = test_genres.to(device)\n",
        "        test_outputs = model(test_images)\n",
        "        test_loss += criterion(test_outputs, test_genres).item()\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "        total += test_genres.size(0)\n",
        "        correct += (predicted == test_genres).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# So Far:\n",
        "# Base Parameters\n",
        "# Test Loss: 1.8366234250484952, Test Accuracy: 0.3923641338142022"
      ],
      "metadata": {
        "id": "iHmG-8PGYdNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}