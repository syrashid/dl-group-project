{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images to Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Action - tt0456980\n",
    "- Action - tt3949660\n",
    "- Action - tt1054122\n",
    "- Adventure - tt1097636\n",
    "- Adventure - tt0096787\n",
    "- Adventure - tt3700456\n",
    "- Animation - tt0285021\n",
    "- Comedy - tt0808146\n",
    "- Comedy - tt3685624\n",
    "- Comedy - tt1182972\n",
    "- Crime - tt3059816\n",
    "- Crime - tt0274711\n",
    "- Crime - tt0482572\n",
    "- Documentary - tt0449786\n",
    "- Documentary - tt0847817\n",
    "- Documentary - tt5525310\n",
    "- Drama - tt0096171\n",
    "- Drama - tt0809427\n",
    "- Drama - tt0098659\n",
    "- Horror - tt2316204\n",
    "- Horror - tt0093177\n",
    "- Horror - tt3181898"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Per Layer (Compared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Action_tt0456980. Check the 'comparison_Action_tt0456980' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Adventure_tt1097636. Check the 'comparison_Adventure_tt1097636' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Animation_tt0285021. Check the 'comparison_Animation_tt0285021' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Comedy_tt0808146. Check the 'comparison_Comedy_tt0808146' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Crime_tt3059816. Check the 'comparison_Crime_tt3059816' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Documentary_tt0449786. Check the 'comparison_Documentary_tt0449786' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Drama_tt0096171. Check the 'comparison_Drama_tt0096171' for results.\n",
      "inception - Conv2d_1a_3x3 feature maps shape: torch.Size([1, 32, 149, 149])\n",
      "inception - Mixed_5b feature maps shape: torch.Size([1, 256, 35, 35])\n",
      "inception - Mixed_6a feature maps shape: torch.Size([1, 768, 17, 17])\n",
      "inception - Mixed_7a feature maps shape: torch.Size([1, 1280, 8, 8])\n",
      "resnet - conv1 feature maps shape: torch.Size([1, 64, 150, 150])\n",
      "resnet - layer1.0.conv1 feature maps shape: torch.Size([1, 64, 75, 75])\n",
      "resnet - layer2.0.conv1 feature maps shape: torch.Size([1, 128, 75, 75])\n",
      "resnet - layer3.0.conv1 feature maps shape: torch.Size([1, 256, 38, 38])\n",
      "Comparison complete for Horror_tt2316204. Check the 'comparison_Horror_tt2316204' for results.\n",
      "Combined image for genre Adventure saved to Adventure_combined.png\n",
      "Combined image for genre Comedy saved to Comedy_combined.png\n",
      "Combined image for genre Drama saved to Drama_combined.png\n",
      "Combined image for genre Crime saved to Crime_combined.png\n",
      "Combined image for genre Animation saved to Animation_combined.png\n",
      "Combined image for genre Horror saved to Horror_combined.png\n",
      "Combined image for genre Documentary saved to Documentary_combined.png\n",
      "Combined image for genre Action saved to Action_combined.png\n",
      "All comparisons complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# Load the checkpoint to determine the number of classes\n",
    "inception_checkpoint = torch.load(\"best_model_inception.pth\")\n",
    "resnet_checkpoint = torch.load(\"best_model_resnet50.pth\")\n",
    "\n",
    "# Extract the number of classes from the checkpoint\n",
    "num_classes_inception = inception_checkpoint[\"fc.weight\"].size(0)\n",
    "num_classes_resnet = resnet_checkpoint[\"fc.weight\"].size(0)\n",
    "\n",
    "# Load the pre-trained InceptionV3 model and modify the final layer\n",
    "inception_model = models.inception_v3(pretrained=False)\n",
    "inception_model.fc = nn.Linear(inception_model.fc.in_features, num_classes_inception)\n",
    "inception_model.load_state_dict(inception_checkpoint)\n",
    "inception_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load the pre-trained ResNet50 model and modify the final layer\n",
    "resnet_model = models.resnet50(pretrained=False)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes_resnet)\n",
    "resnet_model.load_state_dict(resnet_checkpoint)\n",
    "resnet_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Function to register hooks to capture feature maps for specific layers\n",
    "def register_hooks(model, layer_names):\n",
    "    activation = {}\n",
    "    hooks = []\n",
    "\n",
    "    def get_activation(layer_name):\n",
    "        def hook(model, input, output):\n",
    "            activation[layer_name] = output\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if name in layer_names:\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name)))\n",
    "    return activation, hooks\n",
    "\n",
    "\n",
    "# Layers to compare, excluding avgpool\n",
    "inception_layers = [\"Conv2d_1a_3x3\", \"Mixed_5b\", \"Mixed_6a\", \"Mixed_7a\"]\n",
    "resnet_layers = [\"conv1\", \"layer1.0.conv1\", \"layer2.0.conv1\", \"layer3.0.conv1\"]\n",
    "\n",
    "# Register hooks for both models\n",
    "inception_activation, inception_hooks = register_hooks(\n",
    "    inception_model, inception_layers\n",
    ")\n",
    "resnet_activation, resnet_hooks = register_hooks(resnet_model, resnet_layers)\n",
    "\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "# Function to compute and save average activation maps\n",
    "def save_average_activation_maps(\n",
    "    model_name, activation, img_name, layer_names, results_dir, img_size=(299, 299)\n",
    "):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    for layer_name in layer_names:\n",
    "        feature_maps = activation[layer_name]\n",
    "\n",
    "        print(f\"{model_name} - {layer_name} feature maps shape: {feature_maps.shape}\")\n",
    "\n",
    "        # Compute the average activation map for Conv2d layers\n",
    "        if feature_maps.dim() == 4:\n",
    "            avg_activation_map = (\n",
    "                torch.mean(feature_maps, dim=1).squeeze().detach().cpu().numpy()\n",
    "            )\n",
    "        elif feature_maps.dim() == 2:  # For Linear layers\n",
    "            avg_activation_map = feature_maps.squeeze().detach().cpu().numpy()\n",
    "            avg_activation_map = avg_activation_map.reshape((1, -1))\n",
    "\n",
    "        if (\n",
    "            avg_activation_map.size == 1\n",
    "        ):  # Handle case where avg_activation_map is a single value\n",
    "            avg_activation_map = np.full((img_size[0], img_size[1]), avg_activation_map)\n",
    "\n",
    "        avg_activation_map = (avg_activation_map - avg_activation_map.min()) / (\n",
    "            avg_activation_map.max() - avg_activation_map.min()\n",
    "        )\n",
    "\n",
    "        avg_activation_map = np.nan_to_num(avg_activation_map)  # Replace NaNs with 0\n",
    "\n",
    "        # Ensure the activation map is 2D\n",
    "        if avg_activation_map.ndim == 3:\n",
    "            avg_activation_map = avg_activation_map[0]\n",
    "\n",
    "        # Save the average activation map\n",
    "        plt.imsave(\n",
    "            os.path.join(results_dir, f\"{model_name}_{img_name}_{layer_name}.png\"),\n",
    "            avg_activation_map,\n",
    "            cmap=\"viridis\",\n",
    "        )\n",
    "\n",
    "\n",
    "# Function to create side-by-side comparison images\n",
    "def create_comparison_images(\n",
    "    inception_dir,\n",
    "    resnet_dir,\n",
    "    output_dir,\n",
    "    img_name,\n",
    "    genre,\n",
    "    inception_layers,\n",
    "    resnet_layers,\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    comparison_images = []\n",
    "    for inc_layer, res_layer in zip(inception_layers, resnet_layers):\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        inception_img = Image.open(\n",
    "            os.path.join(inception_dir, f\"inception_{img_name}_{inc_layer}.png\")\n",
    "        )\n",
    "        resnet_img = Image.open(\n",
    "            os.path.join(resnet_dir, f\"resnet_{img_name}_{res_layer}.png\")\n",
    "        )\n",
    "\n",
    "        axes[0].imshow(inception_img, cmap=\"viridis\")\n",
    "        axes[0].set_title(f\"InceptionV3 {inc_layer} - {genre} {img_name}\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        axes[1].imshow(resnet_img, cmap=\"viridis\")\n",
    "        axes[1].set_title(f\"ResNet50 {res_layer} - {genre} {img_name}\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        comparison_image_path = os.path.join(\n",
    "            output_dir, f\"{img_name}_{inc_layer}_comparison.png\"\n",
    "        )\n",
    "        plt.savefig(comparison_image_path)\n",
    "        comparison_images.append(comparison_image_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return comparison_images\n",
    "\n",
    "\n",
    "# Function to combine images into a grid layout image per genre\n",
    "def combine_images_per_genre(images, output_path):\n",
    "    images = [Image.open(img) for img in images]\n",
    "\n",
    "    # Determine the number of rows and columns based on the number of images\n",
    "    num_images = len(images)\n",
    "    grid_size = int(np.ceil(np.sqrt(num_images)))\n",
    "\n",
    "    # Ensure all images are of the same size by resizing to the maximum dimensions\n",
    "    max_width, max_height = max(img.size[0] for img in images), max(\n",
    "        img.size[1] for img in images\n",
    "    )\n",
    "    images = [ImageOps.fit(img, (max_width, max_height)) for img in images]\n",
    "\n",
    "    combined_image = Image.new(\"RGB\", (grid_size * max_width, grid_size * max_height))\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        x = (i % grid_size) * max_width\n",
    "        y = (i // grid_size) * max_height\n",
    "        combined_image.paste(img, (x, y))\n",
    "\n",
    "    combined_image.save(output_path)\n",
    "\n",
    "\n",
    "# List of image IDs and genres\n",
    "images_to_compare = [\n",
    "    (\"Action\", \"tt0456980\"),\n",
    "    (\"Adventure\", \"tt1097636\"),\n",
    "    (\"Animation\", \"tt0285021\"),\n",
    "    (\"Comedy\", \"tt0808146\"),\n",
    "    (\"Crime\", \"tt3059816\"),\n",
    "    (\"Documentary\", \"tt0449786\"),\n",
    "    (\"Drama\", \"tt0096171\"),\n",
    "    (\"Horror\", \"tt2316204\"),\n",
    "]\n",
    "\n",
    "# Loop through the Posters directory and its subdirectories\n",
    "root_dir = \"Posters\"\n",
    "for genre, img_id in images_to_compare:\n",
    "    found = False\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.startswith(img_id) and file.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    if found:\n",
    "        img_name = f\"{genre}_{img_id}\"\n",
    "        input_tensor = preprocess_image(img_path)\n",
    "\n",
    "        # Forward pass to capture activations for InceptionV3\n",
    "        inception_model(input_tensor)\n",
    "        inception_results_dir = f\"average_activations_inception_{img_name}\"\n",
    "        save_average_activation_maps(\n",
    "            \"inception\",\n",
    "            inception_activation,\n",
    "            img_name,\n",
    "            inception_layers,\n",
    "            inception_results_dir,\n",
    "        )\n",
    "\n",
    "        # Forward pass to capture activations for ResNet50\n",
    "        resnet_model(input_tensor)\n",
    "        resnet_results_dir = f\"average_activations_resnet_{img_name}\"\n",
    "        save_average_activation_maps(\n",
    "            \"resnet\", resnet_activation, img_name, resnet_layers, resnet_results_dir\n",
    "        )\n",
    "\n",
    "        # Create side-by-side comparison images\n",
    "        output_dir = f\"comparison_{img_name}\"\n",
    "        comparison_images = create_comparison_images(\n",
    "            inception_results_dir,\n",
    "            resnet_results_dir,\n",
    "            output_dir,\n",
    "            img_name,\n",
    "            genre,\n",
    "            inception_layers,\n",
    "            resnet_layers,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Comparison complete for {img_name}. Check the '{output_dir}' for results.\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Image {img_id} not found in genre {genre}.\")\n",
    "\n",
    "# Combine images per genre into one grid layout image\n",
    "for genre in set([g for g, _ in images_to_compare]):\n",
    "    genre_images = []\n",
    "    for g, img_id in images_to_compare:\n",
    "        if g == genre:\n",
    "            img_name = f\"{g}_{img_id}\"\n",
    "            output_dir = f\"comparison_{img_name}\"\n",
    "            comparison_images = [\n",
    "                os.path.join(output_dir, f)\n",
    "                for f in os.listdir(output_dir)\n",
    "                if f.endswith(\".png\")\n",
    "            ]\n",
    "            genre_images.extend(comparison_images)\n",
    "    if genre_images:\n",
    "        output_path = f\"{genre}_combined.png\"\n",
    "        combine_images_per_genre(genre_images, output_path)\n",
    "        print(f\"Combined image for genre {genre} saved to {output_path}\")\n",
    "\n",
    "print(\"All comparisons complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# Load the pre-trained InceptionV3 model and modify the final layer\n",
    "model = models.inception_v3(pretrained=False)\n",
    "num_classes = 13  # Replace with the number of classes in your checkpoint\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"best_model_inception.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Function to register hooks to capture feature maps for all layers\n",
    "def register_hooks(model):\n",
    "    activation = {}\n",
    "    hooks = []\n",
    "\n",
    "    def get_activation(layer_name):\n",
    "        def hook(model, input, output):\n",
    "            activation[layer_name] = output\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name)))\n",
    "    return activation, hooks\n",
    "\n",
    "\n",
    "# Register hooks for all layers\n",
    "activation, hooks = register_hooks(model)\n",
    "\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "# Function to compute and save average activation maps\n",
    "def save_average_activation_maps(model, activation, results_dir, img_size=(299, 299)):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    for idx, layer_name in enumerate(activation.keys()):\n",
    "        print(f\"Computing average activation for layer {layer_name}\")\n",
    "        feature_maps = activation[layer_name]\n",
    "\n",
    "        # Compute the average activation map\n",
    "        if feature_maps.dim() == 4:  # For Conv2d layers\n",
    "            avg_activation_map = (\n",
    "                torch.mean(feature_maps, dim=1).squeeze().detach().cpu().numpy()\n",
    "            )\n",
    "        elif feature_maps.dim() == 2:  # For Linear layers\n",
    "            avg_activation_map = feature_maps.squeeze().detach().cpu().numpy()\n",
    "            avg_activation_map = avg_activation_map.reshape((1, -1))\n",
    "\n",
    "        avg_activation_map = (avg_activation_map - avg_activation_map.min()) / (\n",
    "            avg_activation_map.max() - avg_activation_map.min()\n",
    "        )\n",
    "\n",
    "        # Ensure the activation map is 2D\n",
    "        if avg_activation_map.ndim == 3:\n",
    "            avg_activation_map = avg_activation_map[0]\n",
    "\n",
    "        # Save the average activation map\n",
    "        plt.imsave(\n",
    "            os.path.join(results_dir, f\"{idx:03d}_{layer_name}_avg_activation.png\"),\n",
    "            avg_activation_map,\n",
    "            cmap=\"viridis\",\n",
    "        )\n",
    "\n",
    "\n",
    "# Function to create a GIF from images\n",
    "def create_gif(image_folder, output_path, duration=0.5):\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(image_folder)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(image_folder, file_name)\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img = img.resize((299, 299), Image.LANCZOS)  # Resize to the same dimensions\n",
    "            images.append(np.array(img))\n",
    "\n",
    "    imageio.mimsave(output_path, images, duration=duration)\n",
    "\n",
    "\n",
    "# List of image paths\n",
    "image_paths = [\n",
    "    \"Posters//1979//tt0080180//tt0080180.jpg\",\n",
    "    \"Posters//1981//tt0081256//tt0081256.jpg\",\n",
    "    \"Posters//1992//tt0104389//tt0104389.jpg\",\n",
    "    \"Posters//1988//tt0098415//tt0098415.jpg\",\n",
    "]\n",
    "\n",
    "# Loop through each image, process it, and save the activations in separate folders\n",
    "for img_path in image_paths:\n",
    "    img_name = os.path.basename(img_path).split(\".\")[0]\n",
    "    input_tensor = preprocess_image(img_path)\n",
    "    input_tensor.requires_grad_(True)  # Ensure the input tensor requires gradients\n",
    "\n",
    "    # Forward pass to capture activations\n",
    "    model(input_tensor)\n",
    "\n",
    "    # Directory to save the average activation maps for the current image\n",
    "    results_dir = f\"average_activations_inceptionv3_{img_name}\"\n",
    "\n",
    "    # Save average activation maps for the current image\n",
    "    save_average_activation_maps(model, activation, results_dir)\n",
    "\n",
    "    # Create a GIF from the saved activation maps\n",
    "    gif_output_path = f\"average_activations_inceptionv3_{img_name}.gif\"\n",
    "    create_gif(results_dir, gif_output_path)\n",
    "\n",
    "    print(\n",
    "        f\"Visualization and GIF creation complete for {img_path}. Check the '{results_dir}' and '{gif_output_path}' for results.\"\n",
    "    )\n",
    "\n",
    "print(\"All visualizations and GIFs complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "# Load the pre-trained ResNet model and modify the final layer\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_classes = 13  # Replace with the number of classes in your checkpoint\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(\"best_model_resnet50.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "\n",
    "# Function to register hooks to capture feature maps for all layers\n",
    "def register_hooks(model):\n",
    "    activation = {}\n",
    "    hooks = []\n",
    "\n",
    "    def get_activation(layer_name):\n",
    "        def hook(model, input, output):\n",
    "            activation[layer_name] = output\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name)))\n",
    "    return activation, hooks\n",
    "\n",
    "\n",
    "# Register hooks for all layers\n",
    "activation, hooks = register_hooks(model)\n",
    "\n",
    "\n",
    "# Function to preprocess the input image\n",
    "def preprocess_image(img_path):\n",
    "    preprocess = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((299, 299)),  # Resize to 299x299 to match InceptionV3\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "# Function to compute and save average activation maps\n",
    "def save_average_activation_maps(model, activation, results_dir, img_size=(299, 299)):\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    for idx, layer_name in enumerate(activation.keys()):\n",
    "        print(f\"Computing average activation for layer {layer_name}\")\n",
    "        feature_maps = activation[layer_name]\n",
    "\n",
    "        # Compute the average activation map\n",
    "        if feature_maps.dim() == 4:  # For Conv2d layers\n",
    "            avg_activation_map = (\n",
    "                torch.mean(feature_maps, dim=1).squeeze().detach().cpu().numpy()\n",
    "            )\n",
    "        elif feature_maps.dim() == 2:  # For Linear layers\n",
    "            avg_activation_map = feature_maps.squeeze().detach().cpu().numpy()\n",
    "            avg_activation_map = avg_activation_map.reshape((1, -1))\n",
    "\n",
    "        avg_activation_map = (avg_activation_map - avg_activation_map.min()) / (\n",
    "            avg_activation_map.max() - avg_activation_map.min()\n",
    "        )\n",
    "\n",
    "        # Ensure the activation map is 2D\n",
    "        if avg_activation_map.ndim == 3:\n",
    "            avg_activation_map = avg_activation_map[0]\n",
    "\n",
    "        # Save the average activation map\n",
    "        plt.imsave(\n",
    "            os.path.join(results_dir, f\"{idx:03d}_{layer_name}_avg_activation.png\"),\n",
    "            avg_activation_map,\n",
    "            cmap=\"viridis\",\n",
    "        )\n",
    "\n",
    "\n",
    "# Function to create a GIF from images\n",
    "def create_gif(image_folder, output_path, duration=0.5):\n",
    "    images = []\n",
    "    for file_name in sorted(os.listdir(image_folder)):\n",
    "        if file_name.endswith(\".png\"):\n",
    "            file_path = os.path.join(image_folder, file_name)\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            img = img.resize((299, 299), Image.LANCZOS)  # Resize to the same dimensions\n",
    "            images.append(np.array(img))\n",
    "\n",
    "    imageio.mimsave(output_path, images, duration=duration)\n",
    "\n",
    "\n",
    "# List of image paths\n",
    "image_paths = [\n",
    "    \"Posters//1979//tt0080180//tt0080180.jpg\",\n",
    "    \"Posters//1981//tt0081256//tt0081256.jpg\",\n",
    "    \"Posters//1992//tt0104389//tt0104389.jpg\",\n",
    "    \"Posters//1988//tt0098415//tt0098415.jpg\",\n",
    "]\n",
    "\n",
    "# Loop through each image, process it, and save the activations in separate folders\n",
    "for img_path in image_paths:\n",
    "    img_name = os.path.basename(img_path).split(\".\")[0]\n",
    "    input_tensor = preprocess_image(img_path)\n",
    "    input_tensor.requires_grad_(True)  # Ensure the input tensor requires gradients\n",
    "\n",
    "    # Forward pass to capture activations\n",
    "    model(input_tensor)\n",
    "\n",
    "    # Directory to save the average activation maps for the current image\n",
    "    results_dir = f\"average_activations_resnet_{img_name}\"\n",
    "\n",
    "    # Save average activation maps for the current image\n",
    "    save_average_activation_maps(model, activation, results_dir)\n",
    "\n",
    "    # Create a GIF from the saved activation maps\n",
    "    gif_output_path = f\"average_activations_resnet_{img_name}.gif\"\n",
    "    create_gif(results_dir, gif_output_path)\n",
    "\n",
    "    print(\n",
    "        f\"Visualization and GIF creation complete for {img_path}. Check the '{results_dir}' and '{gif_output_path}' for results.\"\n",
    "    )\n",
    "\n",
    "print(\"All visualizations and GIFs complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
