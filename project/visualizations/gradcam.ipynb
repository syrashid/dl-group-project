{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation & Configuration"
      ],
      "metadata": {
        "id": "c7HrKDOSV2Bq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UFzNDC7UIFd"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!pip install tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "kaggle_json_path = '/content/drive/MyDrive/ColabNotebooks/A5/kaggle.json'\n",
        "\n",
        "# Copy kaggle.json to the correct location\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp {kaggle_json_path} ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Choose the model you want to apply\n",
        "model_type = \"resnet50\" # or \"inceptionv3\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ],
      "metadata": {
        "id": "h6ougqCfWa8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip dataset\n",
        "!kaggle datasets download -d rezaunderfit/48k-imdb-movies-with-posters > /dev/null 2>&1\n",
        "!unzip -q 48k-imdb-movies-with-posters.zip\n",
        "\n",
        "# Load title basics\n",
        "tsv_path = '/content/drive/MyDrive/ColabNotebooks/A5/title.basics.tsv'\n",
        "title_basics = pd.read_csv(tsv_path, sep='\\t', na_values='\\\\N')\n",
        "\n",
        "# List all files in the Poster directory\n",
        "poster_dir = 'Poster'\n",
        "poster_files = []\n",
        "for root, _, files in os.walk(poster_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            if os.path.getsize(file_path) > 0:  # Only include non-zero byte files\n",
        "                poster_files.append(file_path)\n",
        "\n",
        "# Extract tconst and startYear from file paths\n",
        "poster_info = []\n",
        "for file_path in poster_files:\n",
        "    parts = file_path.split('/')\n",
        "    start_year = parts[1]\n",
        "    tconst = parts[2]\n",
        "    poster_info.append((start_year, tconst))\n",
        "\n",
        "# Convert to DataFrame\n",
        "poster_df = pd.DataFrame(poster_info, columns=['startYear', 'tconst'])\n",
        "\n",
        "# Ensure startYear is an integer\n",
        "poster_df['startYear'] = poster_df['startYear'].astype(int)\n",
        "title_basics['startYear'] = title_basics['startYear'].astype(float).fillna(0).astype(int)  # Handle missing startYear and convert to int\n",
        "\n",
        "# Filter movies from the past 50 years\n",
        "current_year = 2024\n",
        "past_50_years = current_year - 50\n",
        "poster_df = poster_df[poster_df['startYear'] >= past_50_years]\n",
        "\n",
        "# Merge with title_basics to keep only relevant records\n",
        "title_basics_filtered = pd.merge(title_basics, poster_df, on=['startYear', 'tconst'])\n",
        "\n",
        "# Function to count genres\n",
        "def count_genres(metadata):\n",
        "    genre_counter = Counter()\n",
        "    for genres in metadata['genres'].dropna():\n",
        "        first_genre = genres.split(',')[0]\n",
        "        genre_counter[first_genre] += 1\n",
        "    return genre_counter\n",
        "\n",
        "# Count genres in the filtered dataset\n",
        "filtered_genre_counts = count_genres(title_basics_filtered)\n",
        "\n",
        "# Calculate total number of movies\n",
        "total_movies = len(title_basics_filtered)\n",
        "\n",
        "# Filter out genres with less than 1% of the total dataset\n",
        "min_count = total_movies * 0.01\n",
        "valid_genres = {genre for genre, count in filtered_genre_counts.items() if count >= min_count}\n",
        "\n",
        "# Filter the dataset to only include valid genres\n",
        "def filter_genres(row):\n",
        "    if pd.notna(row['genres']):\n",
        "        genres = row['genres'].split(',')\n",
        "        if any(genre in valid_genres for genre in genres):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "title_basics_filtered = title_basics_filtered[title_basics_filtered.apply(filter_genres, axis=1)]\n",
        "\n",
        "# Create your data splits\n",
        "train_metadata, test_metadata = train_test_split(title_basics_filtered, test_size=0.2, random_state=42)\n",
        "train_metadata, val_metadata = train_test_split(train_metadata, test_size=0.25, random_state=42)\n",
        "print(f\"Train size: {len(train_metadata)}, Validation size: {len(val_metadata)}, Test size: {len(test_metadata)}\")\n",
        "\n",
        "# Count genres in the training dataset\n",
        "train_genre_counts = count_genres(train_metadata)\n",
        "\n",
        "# Total number of movies in the training dataset\n",
        "train_total_movies = len(train_metadata)\n",
        "\n",
        "# Calculate and print genre distribution with percentages\n",
        "print(\"\\nGenre Distribution in Training Dataset:\")\n",
        "for genre, count in train_genre_counts.items():\n",
        "    percentage = (count / train_total_movies) * 100\n",
        "    print(f\"{genre} - {count} ({percentage:.2f}%)\")\n",
        "\n",
        "# Define the image transformations\n",
        "if model_type == \"inceptionv3\":\n",
        "  image_transforms = transforms.Compose([\n",
        "      transforms.Resize(299),\n",
        "      transforms.CenterCrop(299),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "  ])\n",
        "elif model_type == \"resnet50\":\n",
        "  image_transforms = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
        "\n",
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, metadata, img_dir, transform=None, genre_to_index=None):\n",
        "        self.metadata = metadata\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.genre_to_index = genre_to_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tconst = self.metadata.iloc[idx]['tconst']\n",
        "        start_year = self.metadata.iloc[idx]['startYear']\n",
        "        img_name = os.path.join(self.img_dir, str(start_year), tconst, f\"{tconst}.jpg\")\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        genres = self.metadata.iloc[idx]['genres']\n",
        "        genre_tensor = self.genres_to_tensor(genres)\n",
        "        return image, genre_tensor\n",
        "\n",
        "    def genres_to_tensor(self, genres):\n",
        "        first_genre = genres.split(',')[0] if pd.notna(genres) else 'Unknown'\n",
        "        genre_index = self.genre_to_index.get(first_genre, self.genre_to_index['Unknown'])\n",
        "        return torch.tensor(genre_index, dtype=torch.long)\n",
        "\n",
        "# Create a mapping from genre to index based on the filtered dataset\n",
        "filtered_genres = set(g.split(',')[0] for g in title_basics_filtered['genres'].dropna())\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(filtered_genres)}\n",
        "\n",
        "# Ensure 'Unknown' genre is included in genre_to_index\n",
        "genre_to_index['Unknown'] = len(genre_to_index)\n",
        "\n",
        "# Directory containing images\n",
        "img_dir = 'Poster'\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MovieDataset(metadata=train_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "val_dataset = MovieDataset(metadata=val_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "test_dataset = MovieDataset(metadata=test_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)"
      ],
      "metadata": {
        "id": "D2AzeilmWeAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "59Zg1d8sWAnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# data loader\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "# Set up model for fine tuning\n",
        "if model_type == \"inceptionv3\":\n",
        "  model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"inception_v3\", pretrained=True)\n",
        "  model.aux_logits = False  # Disable auxiliary logits\n",
        "  num_genres = len(genre_to_index)\n",
        "  model.fc = nn.Linear(model.fc.in_features, num_genres)  # Adjust the final layer\n",
        "  path = \"/content/drive/MyDrive/ColabNotebooks/A5/best_model_inception.pth\"\n",
        "elif model_type == \"resnet50\":\n",
        "  model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "  num_genres = len(genre_to_index)\n",
        "  model.fc = nn.Linear(model.fc.in_features, num_genres)  # Adjust the final layer\n",
        "  path = \"/content/drive/MyDrive/ColabNotebooks/A5/best_model_resnet50.pth\"\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Set up loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Load the best model weights\n",
        "model.load_state_dict(\n",
        "    torch.load(path)\n",
        ")\n",
        "\n",
        "# Evaluate on test set and store the best predictions per genre\n",
        "model.eval()\n",
        "best_predictions = {genre: {\"confidence\": 0, \"image_path\": None, \"tconst\": None} for genre in genre_to_index.keys()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
        "    for test_images, test_genres in test_loader_tqdm:\n",
        "        test_images = test_images.to(device)\n",
        "        test_genres = test_genres.to(device)\n",
        "        test_outputs = model(test_images)\n",
        "\n",
        "        for idx in range(test_images.size(0)):\n",
        "            genre = test_genres[idx].item()\n",
        "            confidence = torch.nn.functional.softmax(test_outputs[idx], dim=0)[genre].item()\n",
        "            row = title_basics_filtered.iloc[total + idx]\n",
        "            image_path = row[\"Poster\"]\n",
        "            tconst = row[\"tconst\"]\n",
        "\n",
        "            if confidence > best_predictions[genre][\"confidence\"]:\n",
        "                best_predictions[genre][\"confidence\"] = confidence\n",
        "                best_predictions[genre][\"image_path\"] = image_path\n",
        "                best_predictions[genre][\"tconst\"] = tconst\n",
        "\n",
        "        total += test_genres.size(0)\n"
      ],
      "metadata": {
        "id": "sYriLqVGWCam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GradCAM Analysis"
      ],
      "metadata": {
        "id": "UGYMrPVxWqsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the Image\n",
        "def preprocess_image(img_path):\n",
        "    if model_type == \"inceptionv3\":\n",
        "      preprocess = transforms.Compose(\n",
        "          [\n",
        "              transforms.Resize((299, 299)),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "          ]\n",
        "      )\n",
        "    elif model_type == \"resnet50\":\n",
        "      preprocess = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
        "    return img_tensor\n",
        "\n",
        "# Get the Gradients and Activations\n",
        "def get_gradients_hook(module, grad_input, grad_output):\n",
        "    gradients.append(grad_output[0])\n",
        "\n",
        "def get_activations_hook(module, input, output):\n",
        "    activations.append(output)\n",
        "\n",
        "gradients = []\n",
        "activations = []\n",
        "\n",
        "target_layer = model.Mixed_7c\n",
        "target_layer.register_forward_hook(get_activations_hook)\n",
        "target_layer.register_backward_hook(get_gradients_hook)\n",
        "\n",
        "# Compute Grad-CAM\n",
        "def compute_gradcam(activations, gradients):\n",
        "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
        "    activations = activations[0].squeeze(0).detach()  # Remove batch dimension\n",
        "\n",
        "    for i in range(len(pooled_gradients)):\n",
        "        activations[i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "    heatmap = torch.mean(activations, dim=0).cpu()\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= torch.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "# Visualize the Heatmap side by side with original image\n",
        "def visualize_heatmap(img_path, heatmap, tconst, confidence):\n",
        "    original_img = cv2.imread(img_path)\n",
        "    heatmap_resized = cv2.resize(heatmap.numpy(), (original_img.shape[1], original_img.shape[0]))\n",
        "    heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "    heatmap_resized = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(original_img, 0.5, heatmap_resized, 0.5, 0)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[0].axis(\"off\")\n",
        "    ax[0].set_title(\"Original Image\")\n",
        "\n",
        "    ax[1].imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    ax[1].axis(\"off\")\n",
        "    ax[1].set_title(\"Grad-CAM Heatmap\")\n",
        "\n",
        "    plt.suptitle(f\"tconst: {tconst}, Confidence: {confidence:.4f}\")\n",
        "    plt.show()\n",
        "\n",
        "# Function to generate Grad-CAM heatmap\n",
        "def generate_gradcam_heatmap(image_path, model):\n",
        "    input_tensor = preprocess_image(image_path)\n",
        "\n",
        "    gradients.clear()\n",
        "    activations.clear()\n",
        "\n",
        "    output = model(input_tensor)\n",
        "    pred_class = output.argmax().item()\n",
        "\n",
        "    model.zero_grad()\n",
        "    one_hot_output = torch.zeros((1, output.size()[-1]), dtype=torch.float32)\n",
        "    one_hot_output[0][pred_class] = 1\n",
        "    output.backward(gradient=one_hot_output)\n",
        "\n",
        "    heatmap = compute_gradcam(activations, gradients)\n",
        "    return heatmap\n",
        "\n",
        "# Process each genre and generate heatmap\n",
        "for genre, data in best_predictions.items():\n",
        "    image_path = data[\"image_path\"]\n",
        "    tconst = data[\"tconst\"]\n",
        "    confidence = data[\"confidence\"]\n",
        "    if image_path is not None:\n",
        "        print(f\"Generating Grad-CAM for genre: {genre}\")\n",
        "        heatmap = generate_gradcam_heatmap(image_path, model)\n",
        "        visualize_heatmap(image_path, heatmap, tconst, confidence)\n",
        "    else:\n",
        "        print(f\"No predictions found for genre: {genre}\")"
      ],
      "metadata": {
        "id": "I6UMaTEXWtpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}