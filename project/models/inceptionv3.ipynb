{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNgoPgsqdUbS"
      },
      "source": [
        "# Installations & Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4ko-nsGdUM2"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!pip install tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from torch.optim import Adam\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_curve, average_precision_score\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "kaggle_json_path = '/content/drive/MyDrive/ColabNotebooks/A5/kaggle.json'\n",
        "\n",
        "# Copy kaggle.json to the correct location\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp {kaggle_json_path} ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzTJsWIdMeW"
      },
      "source": [
        "# Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un3zXmMXdLi0"
      },
      "outputs": [],
      "source": [
        "# Download and unzip dataset\n",
        "!kaggle datasets download -d rezaunderfit/48k-imdb-movies-with-posters > /dev/null 2>&1\n",
        "!unzip -q 48k-imdb-movies-with-posters.zip\n",
        "\n",
        "# Load title basics\n",
        "tsv_path = '/content/drive/MyDrive/ColabNotebooks/A5/title.basics.tsv'\n",
        "title_basics = pd.read_csv(tsv_path, sep='\\t', na_values='\\\\N')\n",
        "\n",
        "# List all files in the Poster directory\n",
        "poster_dir = 'Poster'\n",
        "poster_files = []\n",
        "for root, _, files in os.walk(poster_dir):\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            if os.path.getsize(file_path) > 0:  # Only include non-zero byte files\n",
        "                poster_files.append(file_path)\n",
        "\n",
        "# Extract tconst and startYear from file paths\n",
        "poster_info = []\n",
        "for file_path in poster_files:\n",
        "    parts = file_path.split('/')\n",
        "    start_year = parts[1]\n",
        "    tconst = parts[2]\n",
        "    poster_info.append((start_year, tconst))\n",
        "\n",
        "# Convert to DataFrame\n",
        "poster_df = pd.DataFrame(poster_info, columns=['startYear', 'tconst'])\n",
        "\n",
        "# Ensure startYear is an integer\n",
        "poster_df['startYear'] = poster_df['startYear'].astype(int)\n",
        "title_basics['startYear'] = title_basics['startYear'].astype(float).fillna(0).astype(int)  # Handle missing startYear and convert to int\n",
        "\n",
        "# Filter movies from the past 50 years\n",
        "current_year = 2024\n",
        "past_50_years = current_year - 50\n",
        "poster_df = poster_df[poster_df['startYear'] >= past_50_years]\n",
        "\n",
        "# Merge with title_basics to keep only relevant records\n",
        "title_basics_filtered = pd.merge(title_basics, poster_df, on=['startYear', 'tconst'])\n",
        "\n",
        "# Function to count genres\n",
        "def count_genres(metadata):\n",
        "    genre_counter = Counter()\n",
        "    for genres in metadata['genres'].dropna():\n",
        "        first_genre = genres.split(',')[0]\n",
        "        genre_counter[first_genre] += 1\n",
        "    return genre_counter\n",
        "\n",
        "# Count genres in the filtered dataset\n",
        "filtered_genre_counts = count_genres(title_basics_filtered)\n",
        "\n",
        "# Calculate total number of movies\n",
        "total_movies = len(title_basics_filtered)\n",
        "\n",
        "# Filter out genres with less than 1% of the total dataset\n",
        "min_count = total_movies * 0.01\n",
        "valid_genres = {genre for genre, count in filtered_genre_counts.items() if count >= min_count}\n",
        "\n",
        "# Filter the dataset to only include valid genres\n",
        "def filter_genres(row):\n",
        "    if pd.notna(row['genres']):\n",
        "        genres = row['genres'].split(',')\n",
        "        if any(genre in valid_genres for genre in genres):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "title_basics_filtered = title_basics_filtered[title_basics_filtered.apply(filter_genres, axis=1)]\n",
        "\n",
        "# Create your data splits\n",
        "train_metadata, test_metadata = train_test_split(title_basics_filtered, test_size=0.2, random_state=42)\n",
        "train_metadata, val_metadata = train_test_split(train_metadata, test_size=0.25, random_state=42)\n",
        "print(f\"Train size: {len(train_metadata)}, Validation size: {len(val_metadata)}, Test size: {len(test_metadata)}\")\n",
        "\n",
        "# Count genres in the training dataset\n",
        "train_genre_counts = count_genres(train_metadata)\n",
        "\n",
        "# Total number of movies in the training dataset\n",
        "train_total_movies = len(train_metadata)\n",
        "\n",
        "# Calculate and print genre distribution with percentages\n",
        "print(\"\\nGenre Distribution in Training Dataset:\")\n",
        "for genre, count in train_genre_counts.items():\n",
        "    percentage = (count / train_total_movies) * 100\n",
        "    print(f\"{genre} - {count} ({percentage:.2f}%)\")\n",
        "\n",
        "# Define the image transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class MovieDataset(Dataset):\n",
        "    def __init__(self, metadata, img_dir, transform=None, genre_to_index=None):\n",
        "        self.metadata = metadata\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.genre_to_index = genre_to_index\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tconst = self.metadata.iloc[idx]['tconst']\n",
        "        start_year = self.metadata.iloc[idx]['startYear']\n",
        "        img_name = os.path.join(self.img_dir, str(start_year), tconst, f\"{tconst}.jpg\")\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        genres = self.metadata.iloc[idx]['genres']\n",
        "        genre_tensor = self.genres_to_tensor(genres)\n",
        "        return image, genre_tensor\n",
        "\n",
        "    def genres_to_tensor(self, genres):\n",
        "        first_genre = genres.split(',')[0] if pd.notna(genres) else 'Unknown'\n",
        "        genre_index = self.genre_to_index.get(first_genre, self.genre_to_index['Unknown'])\n",
        "        return torch.tensor(genre_index, dtype=torch.long)\n",
        "\n",
        "# Create a mapping from genre to index based on the filtered dataset\n",
        "filtered_genres = set(g.split(',')[0] for g in title_basics_filtered['genres'].dropna())\n",
        "genre_to_index = {genre: idx for idx, genre in enumerate(filtered_genres)}\n",
        "\n",
        "# Ensure 'Unknown' genre is included in genre_to_index\n",
        "genre_to_index['Unknown'] = len(genre_to_index)\n",
        "\n",
        "# Directory containing images\n",
        "img_dir = 'Poster'\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MovieDataset(metadata=train_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "val_dataset = MovieDataset(metadata=val_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n",
        "test_dataset = MovieDataset(metadata=test_metadata, img_dir=img_dir, transform=image_transforms, genre_to_index=genre_to_index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS6gapEHz70v"
      },
      "source": [
        "# Hyper Tuning via Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdpjOnMFz7aI"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "!pip install optuna-integration\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from optuna.trial import TrialState\n",
        "\n",
        "def objective(trial):\n",
        "    # hyperparameters values\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-2)\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Load pretrained model\n",
        "    model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "    model.aux_logits = False\n",
        "    num_genres = len(genre_to_index)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_genres)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 5  # Reduced number of epochs for hyperparameter tuning\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 2  # Early stopping patience\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, genres in train_loader:\n",
        "            images = images.to(device)\n",
        "            genres = genres.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, genres)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_genres in val_loader:\n",
        "                val_images = val_images.to(device)\n",
        "                val_genres = val_genres.to(device)\n",
        "                val_outputs = model(val_images)\n",
        "                val_loss += criterion(val_outputs, val_genres).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        trial.report(val_loss, epoch)\n",
        "\n",
        "        # Pruning\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "# Create the study and optimize\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50, timeout=3600)  # Set a timeout to limit the total tuning time\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best hyperparameters: \", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx4aXRhgaA4S"
      },
      "source": [
        "# Transfer Learning --> Fine Tuning (Training & Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU3JxRHSZ-Rc"
      },
      "outputs": [],
      "source": [
        "# Best Hyperparameters After Grid Search\n",
        "batch_size = 32\n",
        "lr = 2.9829823735090913e-05\n",
        "weight_decay = 7.167993883340144e-06\n",
        "num_epochs = 10\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "# Set up model for fine tuning\n",
        "model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"inception_v3\", pretrained=True)\n",
        "model.aux_logits = False  # Disable auxiliary logits\n",
        "num_genres = len(genre_to_index)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_genres)  # Adjust the final layer\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "# Lists to store losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Training loop with validation\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\", unit=\"epoch\"):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    train_loader_tqdm = tqdm(\n",
        "        train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"\n",
        "    )\n",
        "\n",
        "    for images, genres in train_loader_tqdm:\n",
        "        images = images.to(device)\n",
        "        genres = genres.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, genres)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_images, val_genres in val_loader:\n",
        "            val_images = val_images.to(device)\n",
        "            val_genres = val_genres.to(device)\n",
        "            val_outputs = model(val_images)\n",
        "            val_loss += criterion(val_outputs, val_genres).item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss}, Validation Loss: {val_loss}\"\n",
        "    )\n",
        "\n",
        "    # Save the model if validation loss decreases\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            \"/content/drive/MyDrive/ColabNotebooks/A5/best_model_inception.pth\",\n",
        "        )\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# Plot the learning curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\")\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning Curves\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/ColabNotebooks/A5/inceptionv3_learning_curves.png\")\n",
        "\n",
        "\n",
        "# TODO: If validation continues to increase a certain number of periods, cut training early"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFkRWZLQYbb8"
      },
      "source": [
        "# Transfer Learning --> Fine Tuning (Testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHmG-8PGYdNa"
      },
      "outputs": [],
      "source": [
        "# Helper function to print unique labels\n",
        "def print_unique_labels(all_labels, genre_to_index):\n",
        "    unique_labels_in_data = np.unique(all_labels)\n",
        "    print(\"Unique labels in the dataset:\", unique_labels_in_data)\n",
        "    print(\"Labels in genre_to_index:\", list(genre_to_index.values()))\n",
        "\n",
        "    missing_labels = set(unique_labels_in_data) - set(genre_to_index.values())\n",
        "    extra_labels = set(genre_to_index.values()) - set(unique_labels_in_data)\n",
        "    print(\"Missing labels in genre_to_index:\", missing_labels)\n",
        "    print(\"Extra labels in genre_to_index:\", extra_labels)\n",
        "\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(\n",
        "    torch.load(\"/content/drive/MyDrive/ColabNotebooks/A5/best_model_inception.pth\")\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", unit=\"batch\")\n",
        "    for test_images, test_genres in test_loader_tqdm:\n",
        "        test_images = test_images.to(device)\n",
        "        test_genres = test_genres.to(device)\n",
        "        test_outputs = model(test_images)\n",
        "        test_loss += criterion(test_outputs, test_genres).item()\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "        total += test_genres.size(0)\n",
        "        correct += (predicted == test_genres).sum().item()\n",
        "\n",
        "        # Collect all predictions, true labels, and probabilities for precision-recall curves\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(test_genres.cpu().numpy())\n",
        "        all_probs.extend(torch.softmax(test_outputs, dim=1).cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Print unique labels and find mismatches\n",
        "print_unique_labels(all_labels, genre_to_index)\n",
        "\n",
        "# Adjust the genre_to_index dictionary if necessary\n",
        "# Remove unused labels\n",
        "used_labels = sorted(np.unique(all_labels))\n",
        "genre_to_index = {\n",
        "    genre: idx for genre, idx in genre_to_index.items() if idx in used_labels\n",
        "}\n",
        "\n",
        "# Ensure the number of classes matches the labels\n",
        "assert len(genre_to_index) == len(\n",
        "    np.unique(all_labels)\n",
        "), \"Mismatch in number of genres and labels.\"\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm, display_labels=list(genre_to_index.keys())\n",
        ")\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "disp.plot(ax=ax)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "plt.savefig(\"/content/drive/MyDrive/ColabNotebooks/A5/inceptionv3_confusion_matrix.png\")\n",
        "\n",
        "# Print classification report with F1 score\n",
        "print(\"Classification Report:\")\n",
        "report = classification_report(\n",
        "    all_labels, all_preds, target_names=list(genre_to_index.keys()), output_dict=True\n",
        ")\n",
        "print(\n",
        "    classification_report(\n",
        "        all_labels, all_preds, target_names=list(genre_to_index.keys())\n",
        "    )\n",
        ")\n",
        "\n",
        "# Extract and print the F1 score\n",
        "f1_scores = {genre: report[genre][\"f1-score\"] for genre in genre_to_index.keys()}\n",
        "print(\"F1 Scores:\")\n",
        "for genre, f1 in f1_scores.items():\n",
        "    print(f\"{genre}: {f1:.2f}\")\n",
        "\n",
        "# Plot precision-recall curves for each genre\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i, genre in enumerate(genre_to_index.keys()):\n",
        "    precision, recall, _ = precision_recall_curve(\n",
        "        np.array(all_labels) == i, np.array(all_probs)[:, i]\n",
        "    )\n",
        "    average_precision = average_precision_score(\n",
        "        np.array(all_labels) == i, np.array(all_probs)[:, i]\n",
        "    )\n",
        "    plt.plot(recall, precision, lw=2, label=f\"{genre} (AP={average_precision:.2f})\")\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curves\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "plt.savefig(\n",
        "    \"/content/drive/MyDrive/ColabNotebooks/A5/inceptionv3_precision_recall_curves.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Sfc5VAUC3l"
      },
      "source": [
        "# Gradcam Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-1hELBXUC3l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the Pre-trained InceptionV3 Model\n",
        "model = models.inception_v3(pretrained=True)\n",
        "\n",
        "# Modify the fully connected layer to match the number of classes (27 in this case)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 27)\n",
        "\n",
        "# Load the custom pre-trained model\n",
        "model.load_state_dict(torch.load(\"best_model_inception.pth\"))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Prepare the Image\n",
        "def preprocess_image(img_path):\n",
        "    preprocess = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((299, 299)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "# Pick a random index from title_basics_filtered\n",
        "random_index = np.random.randint(0, len(title_basics_filtered))\n",
        "img_path = title_basics_filtered.iloc[random_index][\"Poster\"]\n",
        "\n",
        "# Print the original poster using matplotlib\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Prepare the image for the model\n",
        "input_tensor = preprocess_image(img_path)\n",
        "\n",
        "\n",
        "# Get the Gradients and Activations\n",
        "def get_gradients_hook(module, grad_input, grad_output):\n",
        "    gradients.append(grad_output[0])\n",
        "\n",
        "\n",
        "def get_activations_hook(module, input, output):\n",
        "    activations.append(output)\n",
        "\n",
        "\n",
        "gradients = []\n",
        "activations = []\n",
        "\n",
        "target_layer = model.Mixed_7c\n",
        "target_layer.register_forward_hook(get_activations_hook)\n",
        "target_layer.register_backward_hook(get_gradients_hook)\n",
        "\n",
        "# Make a Forward Pass and Compute Gradients\n",
        "output = model(input_tensor)\n",
        "pred_class = output.argmax().item()\n",
        "\n",
        "model.zero_grad()\n",
        "one_hot_output = torch.zeros((1, output.size()[-1]), dtype=torch.float32)\n",
        "one_hot_output[0][pred_class] = 1\n",
        "\n",
        "output.backward(gradient=one_hot_output)\n",
        "\n",
        "\n",
        "# Compute Grad-CAM\n",
        "def compute_gradcam(activations, gradients):\n",
        "    pooled_gradients = torch.mean(gradients[0], dim=[0, 2, 3])\n",
        "    activations = activations[0].squeeze(0).detach()  # Remove batch dimension\n",
        "\n",
        "    for i in range(len(pooled_gradients)):\n",
        "        activations[i, :, :] *= pooled_gradients[i]\n",
        "\n",
        "    heatmap = torch.mean(activations, dim=0).cpu()\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= torch.max(heatmap)\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "heatmap = compute_gradcam(activations, gradients)\n",
        "\n",
        "\n",
        "# Visualize the Heatmap\n",
        "def visualize_heatmap(img_path, heatmap):\n",
        "    img = cv2.imread(img_path)\n",
        "    heatmap = cv2.resize(heatmap.numpy(), (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\n",
        "    cv2.imwrite(\"gradcam.jpg\", superimposed_img)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_heatmap(img_path, heatmap)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "qS6gapEHz70v"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}