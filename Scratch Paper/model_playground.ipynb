{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inception_v3 AKA GoogleNet_v3"
      ],
      "metadata": {
        "id": "U8LsGTchrwma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the initial pre trained model from pytorch"
      ],
      "metadata": {
        "id": "OqOLJJLZsJv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KksuOO33rlzq",
        "outputId": "a8e5d295-1adb-416b-d291-e60f4a6baf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /root/.cache/torch/hub/v0.10.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
            "100%|██████████| 104M/104M [00:00<00:00, 281MB/s] \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download an example image of a dog\n",
        "\n"
      ],
      "metadata": {
        "id": "q8EEXz1nsIcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "1CPwa80Zscad"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform the image as needed for the model\n",
        "\n",
        "*All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 299. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]*"
      ],
      "metadata": {
        "id": "bMJ4iohPseWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
      ],
      "metadata": {
        "id": "zfk3j55psrS2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure and run the model, print the probabilities"
      ],
      "metadata": {
        "id": "_olCJQ7Csz7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BgKcMX0s4Fs",
        "outputId": "49637b28-e85a-4682-83b6-fd60b4227414"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.5651e-01,  1.1059e-01, -4.4388e-01, -6.1264e-02, -2.0064e-01,\n",
            "         1.6754e-01,  5.8188e-01,  6.2146e-02, -7.6539e-02, -1.1179e+00,\n",
            "        -2.1889e-01, -5.2645e-01, -1.1834e-01,  6.6330e-02,  8.4940e-01,\n",
            "        -5.3192e-02, -4.7105e-01, -1.8546e-03,  2.7567e-01,  1.6968e-01,\n",
            "         4.4267e-01, -3.8555e-01,  1.3717e-01, -5.2117e-01,  5.6665e-04,\n",
            "        -2.3551e-01, -2.3237e-01, -7.9603e-03,  1.7020e-02, -1.2653e-01,\n",
            "         2.0522e-01, -7.2862e-03,  1.3082e+00, -2.3156e-01,  9.9151e-01,\n",
            "        -7.7928e-01,  4.8959e-01, -4.2294e-01, -2.6668e-01, -1.4976e-01,\n",
            "         3.5121e-01, -1.7511e-01,  1.0286e-01,  4.2324e-01, -1.4387e-01,\n",
            "         1.3311e-02, -4.6578e-01,  3.6011e-01,  1.5231e-01,  2.0301e-01,\n",
            "        -1.3625e-01,  1.4966e-01,  2.8367e-01, -3.7219e-01,  9.7788e-01,\n",
            "         7.9550e-01, -7.4014e-01, -7.8319e-02, -9.5705e-02,  1.2125e-01,\n",
            "        -1.2760e-01,  3.6893e-01, -4.5279e-01, -7.4862e-01, -8.0980e-02,\n",
            "         2.1753e-01,  2.7076e-01,  1.0095e+00,  4.0753e-01, -1.8546e-01,\n",
            "        -9.2394e-02, -1.2552e-01, -1.0432e+00, -4.0878e-01,  1.8458e-01,\n",
            "        -2.7590e-01, -2.9239e-01,  1.5976e-02,  3.0228e-02,  2.0191e-01,\n",
            "        -4.8360e-01, -6.9748e-02,  1.6869e-01, -4.7624e-02,  8.4331e-01,\n",
            "        -3.6753e-01, -3.0169e-01, -3.7144e-01,  2.6940e-01,  3.7330e-01,\n",
            "         1.8101e-01,  3.1422e-01,  4.5393e-01, -1.3222e-01, -2.9521e-01,\n",
            "        -2.7974e-01,  8.4355e-01, -2.3120e-01, -3.1489e-01, -4.3329e-02,\n",
            "         1.5424e-01,  3.1517e-01,  1.8598e-01, -9.7454e-02,  4.7451e-01,\n",
            "        -8.9017e-01, -7.2356e-01,  2.3606e-01,  6.6764e-01,  1.3753e-01,\n",
            "        -2.4285e-01, -2.3948e-02, -5.4352e-02,  4.9087e-01,  4.8547e-02,\n",
            "        -5.9053e-01, -7.7229e-01,  1.3970e-01, -8.2284e-01,  3.9934e-02,\n",
            "         1.7410e-01, -1.0098e+00, -8.1075e-03, -2.6667e-01, -2.9009e-01,\n",
            "        -6.6680e-02, -6.4876e-01,  9.3691e-01,  5.5043e-01,  5.3064e-01,\n",
            "         1.0868e-01,  1.8127e-01,  6.1084e-01, -6.0828e-01,  3.3734e-01,\n",
            "         1.8885e-01,  5.9113e-01, -4.0931e-01, -7.3571e-01, -6.2757e-01,\n",
            "        -2.7514e-01,  2.6561e-01, -7.5754e-01,  2.5280e-01,  9.6164e-01,\n",
            "        -9.4932e-02,  3.0796e-01, -2.6968e-02,  3.5928e-02,  1.7536e-01,\n",
            "        -2.8845e-01,  1.7306e-01,  2.4232e+00, -1.2379e-01,  9.1111e-01,\n",
            "        -8.8116e-01, -5.2235e-02,  2.1027e+00, -6.6020e-01, -2.4732e-01,\n",
            "        -8.5806e-01, -1.3158e+00, -1.1038e+00, -2.4559e-01, -1.3713e-01,\n",
            "        -1.1998e-01, -2.0858e-01, -3.6209e-01, -9.5151e-02,  7.0495e-01,\n",
            "        -2.2344e-01, -1.8383e-01, -8.5330e-01, -1.8128e-01,  1.3058e+00,\n",
            "        -4.8488e-01, -5.6455e-01, -1.9955e-01, -1.6804e-01, -1.4597e-01,\n",
            "        -8.5823e-01, -3.4302e-01, -2.9135e-01, -4.5527e-01, -5.1164e-01,\n",
            "         4.3950e-01,  8.0362e-01, -4.8994e-01, -6.9496e-01, -8.6068e-01,\n",
            "        -4.1634e-01, -4.4600e-01,  2.0697e-01, -1.2262e+00, -4.5367e-01,\n",
            "        -5.2701e-01, -1.1159e+00,  2.6700e-01, -4.5789e-01,  2.8057e-01,\n",
            "         6.0322e-01, -8.8424e-01, -8.8167e-01,  1.4862e+00, -4.6920e-01,\n",
            "        -1.1064e+00, -5.9580e-01,  6.3190e-01, -5.9060e-01, -7.0514e-01,\n",
            "        -3.8806e-01, -6.3165e-01, -2.1046e-01, -1.6585e-01,  6.3872e-01,\n",
            "         3.0672e-02,  4.5972e-01,  8.4113e-02, -5.4631e-02, -1.9033e+00,\n",
            "        -1.1741e-01, -2.3923e-01,  2.5433e+00,  1.7482e+00,  1.3785e+00,\n",
            "        -5.3432e-01,  3.4156e-01, -7.0544e-01,  3.1824e-01, -9.9048e-02,\n",
            "         1.1116e+00,  1.2895e+00,  1.0476e+00, -7.3799e-02, -2.3407e-01,\n",
            "         6.6534e-02,  5.4161e-01, -4.5627e-01, -8.5854e-02, -4.2202e-01,\n",
            "         7.2564e-01,  4.5567e-01, -8.6067e-02, -8.4127e-01, -3.2937e-01,\n",
            "        -5.2817e-01, -4.2816e-01,  5.0012e-01,  3.2713e+00,  2.3989e+00,\n",
            "         1.5340e+00, -2.0768e-01, -1.8463e-01, -2.7996e-01, -1.7784e-01,\n",
            "         2.8288e-01,  5.2902e-01,  2.8749e+00,  8.8517e+00,  4.2007e+00,\n",
            "         2.5312e+00,  3.9907e+00, -3.1206e-01, -6.2288e-01, -2.6206e-01,\n",
            "        -2.3382e-01, -3.2914e-01,  1.7919e-01, -4.0785e-01,  8.2633e-01,\n",
            "         4.6533e+00, -8.9889e-01, -3.8677e-01,  6.1159e-01,  3.4699e-01,\n",
            "        -8.4518e-01, -7.4924e-02,  5.9349e-01, -2.2492e-01,  4.7943e+00,\n",
            "         2.8128e-01, -3.3889e-01, -7.5826e-01,  1.2874e+00, -6.3793e-01,\n",
            "        -7.2081e-01, -1.0328e+00,  2.1837e-01, -5.6810e-02,  1.2889e-01,\n",
            "        -4.6524e-01,  3.7481e-02, -3.6629e-01, -4.8029e-02, -9.9146e-01,\n",
            "        -1.3358e+00,  6.5007e-01, -2.7140e-01, -6.8027e-01, -5.7188e-01,\n",
            "        -5.3489e-01, -3.8513e-01, -6.5401e-02, -2.8461e-01, -1.7807e-01,\n",
            "        -2.9707e-02,  2.4164e-01, -1.8019e-01,  1.8038e-01, -1.5693e-01,\n",
            "        -2.3899e-01,  1.5222e-01, -1.1802e-01, -2.9299e-01,  2.4769e-01,\n",
            "         2.1732e-01, -5.1214e-01,  2.5827e-01, -1.6336e-01, -2.7098e-01,\n",
            "         4.1206e-01, -3.9119e-01, -6.5403e-01,  2.0348e-01, -1.2729e+00,\n",
            "        -4.3387e-01,  1.5434e-01,  3.4261e-01,  8.7142e-01, -4.1655e-02,\n",
            "        -1.8202e-01,  4.0100e-01,  9.8740e-01, -5.0078e-01, -2.0856e-02,\n",
            "        -5.8561e-01, -9.2884e-01, -5.0841e-01,  1.6722e-02, -2.6145e-01,\n",
            "         1.2273e-02, -1.7244e-01, -2.2842e-01, -2.0732e-01, -2.8096e-01,\n",
            "         3.2843e-02,  5.7519e-01,  3.2662e-01, -1.9560e-01, -8.1264e-01,\n",
            "        -5.2303e-01, -1.6569e-01, -4.2060e-01, -1.4223e-01, -2.5915e-01,\n",
            "         1.4213e-01, -8.4196e-02, -2.1344e-01,  7.6737e-01,  5.5170e-01,\n",
            "        -1.0915e+00,  6.3604e-01, -7.3647e-01,  4.3699e-01, -7.7794e-01,\n",
            "        -7.9397e-01, -1.4512e+00, -7.9183e-01, -7.8746e-01, -8.8865e-01,\n",
            "         2.0334e-01, -4.4609e-01, -9.1740e-01,  7.0128e-02, -2.8481e-01,\n",
            "        -3.7711e-01, -9.6885e-01,  1.0905e-01, -4.9874e-01, -1.3002e+00,\n",
            "        -7.6200e-01, -6.5782e-01, -7.3258e-01, -1.0336e+00, -1.2846e+00,\n",
            "        -3.6768e-01, -9.8355e-01, -9.8253e-02, -4.1718e-01, -6.9331e-02,\n",
            "        -3.5725e-01, -3.6580e-01,  2.0996e-01,  5.5350e-01, -2.1349e-01,\n",
            "        -2.6210e-01,  4.5055e-01, -7.4884e-02,  5.1924e-01,  1.7039e-01,\n",
            "        -3.3124e-02, -1.0280e+00,  5.5609e-01,  1.5656e-01,  9.7192e-02,\n",
            "         1.8759e-01, -3.2613e-01, -3.2746e-01,  2.5089e-01, -2.8548e-01,\n",
            "        -5.9825e-01, -1.0248e+00, -5.6611e-01, -3.8449e-01, -4.1691e-01,\n",
            "        -5.8847e-01, -6.2115e-01,  1.9798e-01, -4.6972e-01,  1.3161e-01,\n",
            "        -2.0350e-01, -1.0142e+00, -2.3295e-01,  1.7178e-01, -4.8151e-01,\n",
            "         2.5391e-01,  1.6370e-01,  6.3144e-02, -2.2032e-01,  2.0385e-01,\n",
            "        -1.6493e-01, -3.9713e-01,  2.4375e-01,  1.6438e-01, -7.2600e-01,\n",
            "        -1.0608e-02, -1.8492e-02, -3.1182e-01, -5.3067e-01,  8.1186e-02,\n",
            "         5.7077e-01, -3.0825e-01,  3.8107e-01, -6.4751e-01,  8.9437e-02,\n",
            "         4.7857e-01, -7.9131e-01, -3.4118e-01,  4.7664e-01,  1.5792e-01,\n",
            "        -1.8361e-01, -1.3278e-01,  2.3204e-01, -5.0417e-01, -2.2666e-01,\n",
            "         7.8322e-02,  5.2047e-01,  1.5849e-01, -8.6863e-02,  3.0277e-01,\n",
            "         1.0029e-01, -1.2771e+00,  7.0220e-01,  1.4692e-01,  3.2780e-01,\n",
            "        -3.6185e-01, -6.2030e-01, -8.8795e-01,  4.2950e-01,  1.1388e-01,\n",
            "         3.2828e-01,  8.3609e-02,  7.0502e-02,  8.1235e-01, -8.0722e-01,\n",
            "        -6.8377e-01,  1.3368e+00, -2.6272e-01,  8.9014e-01,  1.6856e-01,\n",
            "        -1.2181e-01,  4.2764e-01, -1.0053e+00,  3.5844e-01,  3.6249e-01,\n",
            "        -8.3017e-01,  2.9843e-01,  4.0807e-02,  3.5093e-01,  1.2039e-03,\n",
            "         1.3492e-02,  4.7957e-01, -5.8912e-01, -2.9003e-01, -1.0193e-01,\n",
            "         7.4129e-01,  2.7073e-01, -4.4867e-01, -1.6060e-01,  4.8371e-01,\n",
            "        -6.3137e-01, -2.1410e-01,  5.1063e-01, -6.9181e-01, -7.4341e-01,\n",
            "         1.9981e-01,  7.1839e-02,  1.0089e-02,  1.4331e-01, -6.6961e-01,\n",
            "         2.4788e-01,  7.8013e-01,  5.2190e-02, -3.9948e-01,  1.6166e-01,\n",
            "         1.0101e-01, -9.3918e-01, -5.3233e-01, -7.2551e-01, -1.2617e+00,\n",
            "        -2.4838e-01,  7.4782e-01,  1.0527e+00, -6.8670e-01, -1.6222e-01,\n",
            "        -4.3248e-01, -5.9981e-01, -7.0349e-01, -3.8015e-01, -5.7941e-01,\n",
            "         3.0779e-01, -2.2043e-02,  3.5152e-01, -2.5244e-01, -6.5107e-04,\n",
            "        -3.0430e-01, -1.0010e+00,  6.5754e-01, -1.9614e-02,  5.2774e-01,\n",
            "        -1.0624e-01, -3.7718e-01, -5.3913e-01,  1.4141e-01,  4.4648e-01,\n",
            "        -3.1668e-01,  3.0845e-01, -9.4843e-02, -6.7827e-01,  2.7442e-01,\n",
            "        -1.5684e-01,  2.8737e-01, -1.1239e-01, -1.1023e+00, -8.0483e-02,\n",
            "        -4.0687e-01,  2.1739e-02,  3.4752e-01,  4.2768e-02,  4.1246e-01,\n",
            "        -2.4200e-01, -9.4692e-01,  5.9648e-01,  4.2506e-01,  2.0497e-01,\n",
            "        -2.1304e-01,  3.5410e-02,  2.6309e-01, -2.9263e-01, -4.8546e-01,\n",
            "        -1.3047e-01, -6.9699e-01,  7.3211e-04,  7.6484e-01, -1.5322e-01,\n",
            "        -3.3321e-01,  3.0928e-01, -1.2385e-01,  3.9664e-01, -2.5885e-01,\n",
            "         6.6176e-02,  2.7467e-01, -1.5583e-01, -2.9270e-03,  6.3932e-01,\n",
            "         4.5707e-01, -7.3810e-01,  3.0175e-01, -5.0016e-01, -7.1205e-02,\n",
            "         4.7782e-01,  4.0010e-02,  6.5582e-01,  4.1178e-01,  4.7483e-01,\n",
            "        -6.1583e-01,  9.2356e-01,  1.2343e-01, -6.0814e-01, -3.6730e-01,\n",
            "        -6.6226e-01, -4.1350e-01,  8.5858e-02, -3.5333e-01,  9.0584e-01,\n",
            "        -2.6771e-01,  9.3516e-01,  2.5816e-01,  5.2702e-01,  1.5163e-01,\n",
            "         1.0952e-01, -9.9405e-02, -1.7098e-02,  3.0747e-02, -5.9313e-01,\n",
            "         3.7208e-02, -9.2491e-01, -5.0201e-01, -5.5666e-01, -5.3689e-01,\n",
            "        -5.1501e-01,  2.1921e-01,  5.5343e-01,  2.3800e-01,  6.1873e-02,\n",
            "         3.1812e-01,  2.5486e-01,  2.5959e-01,  5.3353e-01,  3.2042e-01,\n",
            "         1.0109e-01, -5.5559e-01, -3.7248e-01, -3.0507e-01, -1.5528e+00,\n",
            "        -5.9913e-01,  1.9392e-01, -3.6299e-01, -1.8390e-01,  5.1914e-01,\n",
            "        -2.0601e-01,  1.6173e-01, -4.1841e-01, -5.1195e-01, -1.2980e-01,\n",
            "         6.7652e-01,  5.5873e-01, -5.3562e-01, -3.6468e-01,  3.3139e-01,\n",
            "        -2.2167e-01,  1.1159e-01,  3.5855e-01, -2.2942e-01, -1.3034e-01,\n",
            "        -6.5708e-01,  4.0689e-01, -7.1228e-01, -2.8138e-01,  2.4038e-01,\n",
            "        -4.6935e-01, -2.6561e-02,  4.9903e-01, -8.8043e-01, -5.2644e-01,\n",
            "         1.7369e-01, -4.2498e-01,  7.8734e-01, -5.3808e-01,  3.1028e-01,\n",
            "         2.8572e-01, -3.8250e-01,  9.9558e-01, -1.6036e-01,  3.1547e-01,\n",
            "         5.9127e-01,  5.0631e-01, -1.8734e-01,  1.1761e-01,  6.0281e-01,\n",
            "         5.3001e-01, -4.3973e-01,  8.9447e-01,  1.0984e-01,  2.9631e-01,\n",
            "        -1.7994e-01, -3.8811e-01, -1.0764e-01, -1.8191e-01, -5.4271e-02,\n",
            "         3.7163e-01, -8.1649e-01, -5.9595e-01, -8.2105e-01, -4.2011e-01,\n",
            "         7.8793e-01, -1.8609e-01, -1.3586e-01,  3.9392e-01,  2.2710e-01,\n",
            "        -5.0077e-01, -2.2137e-01, -9.7564e-01,  4.4647e-01, -5.9424e-01,\n",
            "        -1.5327e+00,  6.6576e-01,  3.1942e-02, -3.5017e-01, -6.6290e-01,\n",
            "         1.0012e-01, -5.4828e-02,  1.1086e-01, -1.3056e+00,  2.9040e-01,\n",
            "         2.1148e-02, -3.7325e-01,  3.6469e-01,  5.8436e-01,  5.4574e-01,\n",
            "         1.4830e-01, -6.7842e-01,  4.3416e-01,  8.1210e-01,  9.3978e-01,\n",
            "        -1.6530e-01,  2.9320e-01,  1.0410e-01, -9.7480e-01,  8.0394e-01,\n",
            "        -5.1994e-01,  6.7030e-01, -7.1215e-02,  3.8662e-01, -1.3348e-01,\n",
            "        -5.3408e-01, -2.1753e-01, -3.1245e-02,  5.2624e-01, -6.4374e-01,\n",
            "         7.4187e-01, -9.8146e-02, -2.2643e-01, -8.4775e-01, -1.4532e-01,\n",
            "        -4.9671e-01,  9.6505e-01, -3.6330e-01, -4.5548e-01,  1.7436e-01,\n",
            "        -8.6780e-01, -3.6269e-01, -8.3034e-02, -6.0731e-01, -8.8556e-01,\n",
            "        -5.1988e-01, -1.0689e-01, -1.1735e-01,  7.4833e-01, -3.6480e-01,\n",
            "        -3.6766e-01, -6.3161e-01, -2.2220e-02,  5.7334e-01, -5.0858e-01,\n",
            "         3.6525e-01, -5.8519e-01,  2.4777e-01,  5.8522e-01,  5.8706e-01,\n",
            "        -1.0896e-01, -2.1983e-01, -1.0265e-01, -3.0060e-01,  1.1959e-01,\n",
            "         1.4755e-02,  1.7697e-01, -1.7402e-02, -5.2798e-01,  6.8920e-03,\n",
            "         8.5859e-01, -9.0237e-02,  8.8717e-02, -5.2276e-01,  1.6984e-01,\n",
            "        -7.0203e-02, -3.6097e-01, -4.3601e-01,  7.3874e-01,  9.7814e-03,\n",
            "         4.0904e-02,  3.1824e-01,  4.9827e-01, -3.8304e-01, -5.5425e-01,\n",
            "        -3.9080e-01, -5.0621e-01, -8.1008e-01, -2.1446e-01,  4.6733e-01,\n",
            "         8.0762e-02, -2.4325e-02,  2.2353e-01,  1.7842e-01, -6.6764e-01,\n",
            "         1.0837e-02, -1.0318e+00, -8.4255e-01,  8.4048e-02,  1.9996e-01,\n",
            "         8.5284e-01, -4.4030e-01,  1.2977e-01,  9.2050e-01,  5.6913e-01,\n",
            "         5.6980e-01,  2.3825e-01, -9.6369e-03, -2.6883e-01, -4.3388e-01,\n",
            "        -3.1661e-01, -6.7593e-01,  9.0054e-02, -3.8565e-01,  1.8710e-01,\n",
            "         4.2990e-01,  1.6977e-01, -2.1813e-01,  4.9394e-01, -6.4244e-01,\n",
            "        -1.9928e-01,  3.0078e-01,  6.5338e-01,  1.3347e-01, -4.5377e-01,\n",
            "        -4.3908e-01,  9.3096e-01,  4.9474e-02,  7.8993e-01, -2.7955e-01,\n",
            "        -1.2904e-01, -1.1084e-01, -1.0125e-02,  9.0992e-01,  1.1985e+00,\n",
            "        -2.4650e-01, -4.1837e-01, -7.1763e-01,  1.0304e-01, -1.7414e-01,\n",
            "        -3.5597e-01, -8.4420e-01,  1.1740e+00,  5.6920e-01,  2.5357e-01,\n",
            "        -4.8572e-01, -5.6443e-01,  5.7963e-01,  5.7453e-01, -7.5991e-02,\n",
            "         1.5547e-01,  1.7221e-01, -3.4962e-01,  1.6330e-01, -8.3248e-01,\n",
            "        -9.8642e-01, -6.0250e-01, -1.2547e-01, -1.7446e+00, -3.2498e-01,\n",
            "         3.0824e-01, -3.3991e-01,  3.0064e-02, -1.3937e-01, -2.8268e-01,\n",
            "        -4.5136e-01, -3.4750e-01, -1.0021e+00,  4.8857e-01,  2.7527e-02,\n",
            "        -1.0133e+00, -4.7256e-01, -8.9813e-02, -1.0510e+00, -1.0173e-01,\n",
            "         3.9033e-02,  1.4560e-01, -2.0656e-01,  9.8666e-02,  4.6666e-01,\n",
            "        -5.9331e-02,  6.0591e-02,  5.6358e-02,  6.5859e-01, -6.9025e-01,\n",
            "        -3.5992e-01,  6.2237e-01,  2.5873e-01,  6.1849e-01,  2.0740e-01,\n",
            "         3.7663e-02, -9.7121e-01,  3.3422e-01, -8.0684e-01, -4.2369e-01,\n",
            "        -4.4443e-01, -1.5185e-01,  2.7905e-01, -1.5228e-02, -1.8445e-01,\n",
            "         6.1413e-01,  2.7279e-01,  5.0746e-01,  8.9932e-01,  4.3446e-01,\n",
            "         7.4836e-01, -3.2950e-02, -4.8579e-01,  1.8002e-02,  9.8718e-02,\n",
            "        -7.8181e-02,  2.5642e-01,  5.0781e-01,  5.3092e-01, -5.5355e-01,\n",
            "         1.4155e-01, -2.6860e-01, -4.0960e-01, -5.3898e-02,  5.2089e-01,\n",
            "         6.1879e-01, -7.5213e-01, -6.7096e-01, -6.2278e-01, -7.4431e-01,\n",
            "         2.0521e-01, -2.5819e-01,  2.4577e-01, -3.3604e-01,  7.6245e-01,\n",
            "         3.1443e-01,  5.6585e-01,  6.5827e-01, -8.0472e-02,  7.7523e-01,\n",
            "         6.8367e-01,  1.8036e-01, -5.7802e-01,  2.3011e-01,  1.8262e-01,\n",
            "         5.3241e-01,  1.0675e-01,  5.9113e-01,  1.6684e-01,  3.3452e-01,\n",
            "         2.4277e-01,  3.7956e-01,  2.3650e-01,  8.2554e-02, -1.6207e-01,\n",
            "        -2.0932e-01,  3.6062e-01,  1.7505e-01, -2.2415e-02, -3.1624e-01,\n",
            "        -3.0932e-01,  2.6022e-01,  1.6403e-01, -8.3430e-01,  2.4436e-01,\n",
            "        -1.8079e-02, -5.8741e-02,  5.7920e-01,  2.4941e-02,  1.6831e-01,\n",
            "        -2.6750e-01,  1.6958e-01,  1.3022e+00,  7.3701e-01,  2.6301e-01,\n",
            "        -2.7585e-01, -2.4151e-01, -2.1679e-01,  1.6225e-01, -3.1854e-01,\n",
            "         3.9116e-02,  1.4038e-01, -4.0891e-01,  1.9361e-01, -9.6223e-02,\n",
            "        -3.0682e-01, -3.9123e-01, -1.9004e-01, -9.0451e-01, -8.7374e-01,\n",
            "        -4.3420e-01, -7.6235e-02, -8.3219e-01, -5.2272e-01,  1.1744e-01],\n",
            "       device='cuda:0')\n",
            "tensor([1.3787e-04, 1.3168e-04, 7.5637e-05, 1.1089e-04, 9.6465e-05, 1.3940e-04,\n",
            "        2.1097e-04, 1.2546e-04, 1.0921e-04, 3.8547e-05, 9.4720e-05, 6.9642e-05,\n",
            "        1.0474e-04, 1.2598e-04, 2.7567e-04, 1.1179e-04, 7.3609e-05, 1.1768e-04,\n",
            "        1.5532e-04, 1.3970e-04, 1.8355e-04, 8.0180e-05, 1.3523e-04, 7.0011e-05,\n",
            "        1.1796e-04, 9.3160e-05, 9.3452e-05, 1.1696e-04, 1.1992e-04, 1.0389e-04,\n",
            "        1.4475e-04, 1.1704e-04, 4.3617e-04, 9.3528e-05, 3.1777e-04, 5.4084e-05,\n",
            "        1.9237e-04, 7.7237e-05, 9.0300e-05, 1.0150e-04, 1.6751e-04, 9.8959e-05,\n",
            "        1.3067e-04, 1.8002e-04, 1.0210e-04, 1.1948e-04, 7.3998e-05, 1.6901e-04,\n",
            "        1.3729e-04, 1.4443e-04, 1.0288e-04, 1.3693e-04, 1.5657e-04, 8.1258e-05,\n",
            "        3.1347e-04, 2.6121e-04, 5.6243e-05, 1.0902e-04, 1.0714e-04, 1.3310e-04,\n",
            "        1.0377e-04, 1.7050e-04, 7.4966e-05, 5.5768e-05, 1.0873e-04, 1.4655e-04,\n",
            "        1.5456e-04, 3.2355e-04, 1.7721e-04, 9.7941e-05, 1.0749e-04, 1.0399e-04,\n",
            "        4.1540e-05, 7.8338e-05, 1.4180e-04, 8.9472e-05, 8.8008e-05, 1.1980e-04,\n",
            "        1.2152e-04, 1.4428e-04, 7.2691e-05, 1.0995e-04, 1.3956e-04, 1.1241e-04,\n",
            "        2.7400e-04, 8.1637e-05, 8.7194e-05, 8.1319e-05, 1.5435e-04, 1.7125e-04,\n",
            "        1.4129e-04, 1.6142e-04, 1.8563e-04, 1.0330e-04, 8.7760e-05, 8.9129e-05,\n",
            "        2.7407e-04, 9.3562e-05, 8.6050e-05, 1.1290e-04, 1.3756e-04, 1.6158e-04,\n",
            "        1.4200e-04, 1.0695e-04, 1.8949e-04, 4.8407e-05, 5.7183e-05, 1.4929e-04,\n",
            "        2.2986e-04, 1.3528e-04, 9.2477e-05, 1.1511e-04, 1.1166e-04, 1.9261e-04,\n",
            "        1.2376e-04, 6.5319e-05, 5.4463e-05, 1.3557e-04, 5.1779e-05, 1.2270e-04,\n",
            "        1.4032e-04, 4.2949e-05, 1.1695e-04, 9.0301e-05, 8.8211e-05, 1.1029e-04,\n",
            "        6.1624e-05, 3.0089e-04, 2.0443e-04, 2.0043e-04, 1.3143e-04, 1.4133e-04,\n",
            "        2.1716e-04, 6.4170e-05, 1.6520e-04, 1.4240e-04, 2.1293e-04, 7.8297e-05,\n",
            "        5.6493e-05, 6.2944e-05, 8.9540e-05, 1.5376e-04, 5.5273e-05, 1.5181e-04,\n",
            "        3.0842e-04, 1.0722e-04, 1.6042e-04, 1.1476e-04, 1.2221e-04, 1.4050e-04,\n",
            "        8.8355e-05, 1.4017e-04, 1.3301e-03, 1.0417e-04, 2.9322e-04, 4.8845e-05,\n",
            "        1.1190e-04, 9.6534e-04, 6.0924e-05, 9.2066e-05, 4.9987e-05, 3.1626e-05,\n",
            "        3.9094e-05, 9.2224e-05, 1.0279e-04, 1.0457e-04, 9.5702e-05, 8.2083e-05,\n",
            "        1.0720e-04, 2.3860e-04, 9.4291e-05, 9.8101e-05, 5.0225e-05, 9.8351e-05,\n",
            "        4.3512e-04, 7.2598e-05, 6.7038e-05, 9.6570e-05, 9.9661e-05, 1.0189e-04,\n",
            "        4.9978e-05, 8.3663e-05, 8.8100e-05, 7.4780e-05, 7.0681e-05, 1.8297e-04,\n",
            "        2.6334e-04, 7.2232e-05, 5.8842e-05, 4.9856e-05, 7.7748e-05, 7.5476e-05,\n",
            "        1.4501e-04, 3.4591e-05, 7.4900e-05, 6.9603e-05, 3.8625e-05, 1.5398e-04,\n",
            "        7.4584e-05, 1.5608e-04, 2.1552e-04, 4.8695e-05, 4.8820e-05, 5.2114e-04,\n",
            "        7.3745e-05, 3.8995e-05, 6.4976e-05, 2.2179e-04, 6.5315e-05, 5.8246e-05,\n",
            "        7.9979e-05, 6.2688e-05, 9.5523e-05, 9.9880e-05, 2.2330e-04, 1.2157e-04,\n",
            "        1.8671e-04, 1.2824e-04, 1.1163e-04, 1.7576e-05, 1.0484e-04, 9.2814e-05,\n",
            "        1.4999e-03, 6.7721e-04, 4.6794e-04, 6.9096e-05, 1.6590e-04, 5.8229e-05,\n",
            "        1.6208e-04, 1.0678e-04, 3.5830e-04, 4.2809e-04, 3.3609e-04, 1.0951e-04,\n",
            "        9.3293e-05, 1.2601e-04, 2.0264e-04, 7.4705e-05, 1.0820e-04, 7.7308e-05,\n",
            "        2.4358e-04, 1.8595e-04, 1.0818e-04, 5.0833e-05, 8.4813e-05, 6.9522e-05,\n",
            "        7.6835e-05, 1.9440e-04, 3.1062e-03, 1.2981e-03, 5.4668e-04, 9.5788e-05,\n",
            "        9.8022e-05, 8.9108e-05, 9.8689e-05, 1.5644e-04, 2.0010e-04, 2.0896e-03,\n",
            "        8.2368e-01, 7.8676e-03, 1.4818e-03, 6.3771e-03, 8.6294e-05, 6.3240e-05,\n",
            "        9.0718e-05, 9.3316e-05, 8.4832e-05, 1.4104e-04, 7.8412e-05, 2.6939e-04,\n",
            "        1.2372e-02, 4.7987e-05, 8.0082e-05, 2.1733e-04, 1.6680e-04, 5.0635e-05,\n",
            "        1.0939e-04, 2.1343e-04, 9.4151e-05, 1.4245e-02, 1.5619e-04, 8.4010e-05,\n",
            "        5.5233e-05, 4.2717e-04, 6.2296e-05, 5.7341e-05, 4.1971e-05, 1.4667e-04,\n",
            "        1.1139e-04, 1.3412e-04, 7.4038e-05, 1.2240e-04, 8.1739e-05, 1.1237e-04,\n",
            "        4.3744e-05, 3.1000e-05, 2.2585e-04, 8.9875e-05, 5.9713e-05, 6.6549e-05,\n",
            "        6.9057e-05, 8.0214e-05, 1.1043e-04, 8.8696e-05, 9.8667e-05, 1.1445e-04,\n",
            "        1.5012e-04, 9.8457e-05, 1.4120e-04, 1.0077e-04, 9.2836e-05, 1.3728e-04,\n",
            "        1.0477e-04, 8.7956e-05, 1.5103e-04, 1.4652e-04, 7.0646e-05, 1.5264e-04,\n",
            "        1.0013e-04, 8.9912e-05, 1.7802e-04, 7.9728e-05, 6.1300e-05, 1.4450e-04,\n",
            "        3.3014e-05, 7.6397e-05, 1.3757e-04, 1.6607e-04, 2.8181e-04, 1.1309e-04,\n",
            "        9.8278e-05, 1.7606e-04, 3.1647e-04, 7.1453e-05, 1.1546e-04, 6.5641e-05,\n",
            "        4.6571e-05, 7.0909e-05, 1.1989e-04, 9.0774e-05, 1.1935e-04, 9.9224e-05,\n",
            "        9.3822e-05, 9.5823e-05, 8.9020e-05, 1.2183e-04, 2.0956e-04, 1.6344e-04,\n",
            "        9.6952e-05, 5.2310e-05, 6.9880e-05, 9.9896e-05, 7.7418e-05, 1.0227e-04,\n",
            "        9.0983e-05, 1.3590e-04, 1.0838e-04, 9.5238e-05, 2.5396e-04, 2.0469e-04,\n",
            "        3.9581e-05, 2.2271e-04, 5.6450e-05, 1.8251e-04, 5.4156e-05, 5.3295e-05,\n",
            "        2.7623e-05, 5.3410e-05, 5.3643e-05, 4.8481e-05, 1.4448e-04, 7.5470e-05,\n",
            "        4.7107e-05, 1.2646e-04, 8.8678e-05, 8.0859e-05, 4.4745e-05, 1.3148e-04,\n",
            "        7.1599e-05, 3.2125e-05, 5.5027e-05, 6.1069e-05, 5.6670e-05, 4.1940e-05,\n",
            "        3.2630e-05, 8.1625e-05, 4.4092e-05, 1.0686e-04, 7.7683e-05, 1.1000e-04,\n",
            "        8.2481e-05, 8.1778e-05, 1.4544e-04, 2.0506e-04, 9.5233e-05, 9.0714e-05,\n",
            "        1.8500e-04, 1.0939e-04, 1.9816e-04, 1.3980e-04, 1.1406e-04, 4.2175e-05,\n",
            "        2.0560e-04, 1.3788e-04, 1.2993e-04, 1.4223e-04, 8.5088e-05, 8.4976e-05,\n",
            "        1.5152e-04, 8.8618e-05, 6.4817e-05, 4.2311e-05, 6.6934e-05, 8.0264e-05,\n",
            "        7.7704e-05, 6.5454e-05, 6.3349e-05, 1.4371e-04, 7.3707e-05, 1.3448e-04,\n",
            "        9.6189e-05, 4.2762e-05, 9.3398e-05, 1.3999e-04, 7.2843e-05, 1.5198e-04,\n",
            "        1.3887e-04, 1.2558e-04, 9.4585e-05, 1.4456e-04, 9.9971e-05, 7.9257e-05,\n",
            "        1.5044e-04, 1.3896e-04, 5.7044e-05, 1.1665e-04, 1.1574e-04, 8.6315e-05,\n",
            "        6.9349e-05, 1.2787e-04, 2.0863e-04, 8.6624e-05, 1.7258e-04, 6.1702e-05,\n",
            "        1.2893e-04, 1.9026e-04, 5.3437e-05, 8.3818e-05, 1.8989e-04, 1.3807e-04,\n",
            "        9.8122e-05, 1.0324e-04, 1.4869e-04, 7.1211e-05, 9.3987e-05, 1.2750e-04,\n",
            "        1.9840e-04, 1.3815e-04, 1.0809e-04, 1.5959e-04, 1.3034e-04, 3.2876e-05,\n",
            "        2.3794e-04, 1.3656e-04, 1.6363e-04, 8.2103e-05, 6.3404e-05, 4.8515e-05,\n",
            "        1.8115e-04, 1.3212e-04, 1.6371e-04, 1.2818e-04, 1.2651e-04, 2.6565e-04,\n",
            "        5.2594e-05, 5.9504e-05, 4.4880e-04, 9.0658e-05, 2.8714e-04, 1.3954e-04,\n",
            "        1.0438e-04, 1.8081e-04, 4.3143e-05, 1.6872e-04, 1.6941e-04, 5.1401e-05,\n",
            "        1.5890e-04, 1.2281e-04, 1.6746e-04, 1.1804e-04, 1.1950e-04, 1.9045e-04,\n",
            "        6.5411e-05, 8.8216e-05, 1.0647e-04, 2.4742e-04, 1.5455e-04, 7.5275e-05,\n",
            "        1.0041e-04, 1.9124e-04, 6.2705e-05, 9.5175e-05, 1.9646e-04, 5.9028e-05,\n",
            "        5.6059e-05, 1.4397e-04, 1.2668e-04, 1.1909e-04, 1.3606e-04, 6.0353e-05,\n",
            "        1.5106e-04, 2.5722e-04, 1.2421e-04, 7.9070e-05, 1.3858e-04, 1.3043e-04,\n",
            "        4.6092e-05, 6.9233e-05, 5.7071e-05, 3.3385e-05, 9.1967e-05, 2.4905e-04,\n",
            "        3.3782e-04, 5.9330e-05, 1.0024e-04, 7.6504e-05, 6.4716e-05, 5.8342e-05,\n",
            "        8.0613e-05, 6.6050e-05, 1.6039e-04, 1.1533e-04, 1.6756e-04, 9.1595e-05,\n",
            "        1.1782e-04, 8.6966e-05, 4.3327e-05, 2.2755e-04, 1.1561e-04, 1.9985e-04,\n",
            "        1.0602e-04, 8.0854e-05, 6.8765e-05, 1.3581e-04, 1.8425e-04, 8.5896e-05,\n",
            "        1.6050e-04, 1.0723e-04, 5.9832e-05, 1.5513e-04, 1.0078e-04, 1.5715e-04,\n",
            "        1.0537e-04, 3.9156e-05, 1.0878e-04, 7.8489e-05, 1.2049e-04, 1.6689e-04,\n",
            "        1.2305e-04, 1.7809e-04, 9.2556e-05, 4.5737e-05, 2.1407e-04, 1.8035e-04,\n",
            "        1.4472e-04, 9.5276e-05, 1.2215e-04, 1.5338e-04, 8.7987e-05, 7.2556e-05,\n",
            "        1.0348e-04, 5.8723e-05, 1.1798e-04, 2.5332e-04, 1.0115e-04, 8.4488e-05,\n",
            "        1.6063e-04, 1.0416e-04, 1.7529e-04, 9.1010e-05, 1.2596e-04, 1.5516e-04,\n",
            "        1.0089e-04, 1.1755e-04, 2.2344e-04, 1.8621e-04, 5.6358e-05, 1.5942e-04,\n",
            "        7.1497e-05, 1.0979e-04, 1.9012e-04, 1.2271e-04, 2.2716e-04, 1.7797e-04,\n",
            "        1.8955e-04, 6.3687e-05, 2.9690e-04, 1.3339e-04, 6.4179e-05, 8.1656e-05,\n",
            "        6.0798e-05, 7.7969e-05, 1.2847e-04, 8.2805e-05, 2.9168e-04, 9.0207e-05,\n",
            "        3.0036e-04, 1.5262e-04, 1.9971e-04, 1.3720e-04, 1.3154e-04, 1.0674e-04,\n",
            "        1.1590e-04, 1.2158e-04, 6.5150e-05, 1.2237e-04, 4.6754e-05, 7.1365e-05,\n",
            "        6.7570e-05, 6.8919e-05, 7.0444e-05, 1.4679e-04, 2.0505e-04, 1.4958e-04,\n",
            "        1.2542e-04, 1.6206e-04, 1.5212e-04, 1.5284e-04, 2.0101e-04, 1.6243e-04,\n",
            "        1.3044e-04, 6.7642e-05, 8.1235e-05, 8.6899e-05, 2.4954e-05, 6.4760e-05,\n",
            "        1.4313e-04, 8.2009e-05, 9.8093e-05, 1.9814e-04, 9.5949e-05, 1.3859e-04,\n",
            "        7.7588e-05, 7.0659e-05, 1.0355e-04, 2.3191e-04, 2.0614e-04, 6.9006e-05,\n",
            "        8.1871e-05, 1.6422e-04, 9.4457e-05, 1.3182e-04, 1.6874e-04, 9.3728e-05,\n",
            "        1.0349e-04, 6.1114e-05, 1.7710e-04, 5.7832e-05, 8.8983e-05, 1.4994e-04,\n",
            "        7.3734e-05, 1.1481e-04, 1.9419e-04, 4.8881e-05, 6.9642e-05, 1.4026e-04,\n",
            "        7.7079e-05, 2.5908e-04, 6.8837e-05, 1.6079e-04, 1.5689e-04, 8.0425e-05,\n",
            "        3.1907e-04, 1.0043e-04, 1.6163e-04, 2.1296e-04, 1.9561e-04, 9.7756e-05,\n",
            "        1.3261e-04, 2.1543e-04, 2.0030e-04, 7.5951e-05, 2.8838e-04, 1.3159e-04,\n",
            "        1.5856e-04, 9.8482e-05, 7.9975e-05, 1.0587e-04, 9.8288e-05, 1.1167e-04,\n",
            "        1.7096e-04, 5.2108e-05, 6.4966e-05, 5.1872e-05, 7.7456e-05, 2.5924e-04,\n",
            "        9.7878e-05, 1.0292e-04, 1.7482e-04, 1.4796e-04, 7.1454e-05, 9.4485e-05,\n",
            "        4.4442e-05, 1.8425e-04, 6.5078e-05, 2.5461e-05, 2.2943e-04, 1.2172e-04,\n",
            "        8.3067e-05, 6.0759e-05, 1.3031e-04, 1.1161e-04, 1.3172e-04, 3.1951e-05,\n",
            "        1.5762e-04, 1.2042e-04, 8.1172e-05, 1.6978e-04, 2.1149e-04, 2.0348e-04,\n",
            "        1.3675e-04, 5.9823e-05, 1.8200e-04, 2.6558e-04, 3.0175e-04, 9.9934e-05,\n",
            "        1.5807e-04, 1.3083e-04, 4.4479e-05, 2.6342e-04, 7.0097e-05, 2.3047e-04,\n",
            "        1.0979e-04, 1.7355e-04, 1.0317e-04, 6.9113e-05, 9.4849e-05, 1.1427e-04,\n",
            "        1.9955e-04, 6.1934e-05, 2.4757e-04, 1.0688e-04, 9.4008e-05, 5.0505e-05,\n",
            "        1.0195e-04, 7.1744e-05, 3.0947e-04, 8.1984e-05, 7.4764e-05, 1.4036e-04,\n",
            "        4.9502e-05, 8.2033e-05, 1.0850e-04, 6.4233e-05, 4.8631e-05, 7.0101e-05,\n",
            "        1.0595e-04, 1.0484e-04, 2.4917e-04, 8.1860e-05, 8.1627e-05, 6.2690e-05,\n",
            "        1.1531e-04, 2.0917e-04, 7.0897e-05, 1.6988e-04, 6.5669e-05, 1.5105e-04,\n",
            "        2.1167e-04, 2.1206e-04, 1.0573e-04, 9.4631e-05, 1.0640e-04, 8.7288e-05,\n",
            "        1.3288e-04, 1.1965e-04, 1.4072e-04, 1.1586e-04, 6.9536e-05, 1.1871e-04,\n",
            "        2.7822e-04, 1.0772e-04, 1.2884e-04, 6.9899e-05, 1.3972e-04, 1.0990e-04,\n",
            "        8.2175e-05, 7.6234e-05, 2.4679e-04, 1.1906e-04, 1.2282e-04, 1.6208e-04,\n",
            "        1.9404e-04, 8.0381e-05, 6.7733e-05, 7.9760e-05, 7.1066e-05, 5.2443e-05,\n",
            "        9.5141e-05, 1.8813e-04, 1.2781e-04, 1.1506e-04, 1.4743e-04, 1.4093e-04,\n",
            "        6.0472e-05, 1.1918e-04, 4.2014e-05, 5.0768e-05, 1.2824e-04, 1.4399e-04,\n",
            "        2.7663e-04, 7.5908e-05, 1.3423e-04, 2.9599e-04, 2.0829e-04, 2.0843e-04,\n",
            "        1.4961e-04, 1.1677e-04, 9.0106e-05, 7.6397e-05, 8.5902e-05, 5.9972e-05,\n",
            "        1.2901e-04, 8.0172e-05, 1.4216e-04, 1.8122e-04, 1.3971e-04, 9.4792e-05,\n",
            "        1.9321e-04, 6.2015e-05, 9.6596e-05, 1.5927e-04, 2.2660e-04, 1.3473e-04,\n",
            "        7.4892e-05, 7.6000e-05, 2.9910e-04, 1.2388e-04, 2.5976e-04, 8.9146e-05,\n",
            "        1.0362e-04, 1.0553e-04, 1.1671e-04, 2.9287e-04, 3.9083e-04, 9.2141e-05,\n",
            "        7.7591e-05, 5.7523e-05, 1.3069e-04, 9.9055e-05, 8.2586e-05, 5.0685e-05,\n",
            "        3.8140e-04, 2.0831e-04, 1.5193e-04, 7.2537e-05, 6.7046e-05, 2.1049e-04,\n",
            "        2.0942e-04, 1.0927e-04, 1.3773e-04, 1.4005e-04, 8.3113e-05, 1.3881e-04,\n",
            "        5.1282e-05, 4.3965e-05, 6.4542e-05, 1.0400e-04, 2.0598e-05, 8.5186e-05,\n",
            "        1.6046e-04, 8.3923e-05, 1.2150e-04, 1.0256e-04, 8.8866e-05, 7.5073e-05,\n",
            "        8.3289e-05, 4.3279e-05, 1.9217e-04, 1.2119e-04, 4.2798e-05, 7.3498e-05,\n",
            "        1.0777e-04, 4.1214e-05, 1.0649e-04, 1.2259e-04, 1.3638e-04, 9.5895e-05,\n",
            "        1.3012e-04, 1.8801e-04, 1.1111e-04, 1.2526e-04, 1.2473e-04, 2.2779e-04,\n",
            "        5.9120e-05, 8.2261e-05, 2.1968e-04, 1.5271e-04, 2.1883e-04, 1.4507e-04,\n",
            "        1.2242e-04, 4.4639e-05, 1.6469e-04, 5.2614e-05, 7.7179e-05, 7.5595e-05,\n",
            "        1.0129e-04, 1.5585e-04, 1.1612e-04, 9.8039e-05, 2.1788e-04, 1.5487e-04,\n",
            "        1.9584e-04, 2.8978e-04, 1.8205e-04, 2.4918e-04, 1.1408e-04, 7.2532e-05,\n",
            "        1.2004e-04, 1.3013e-04, 1.0903e-04, 1.5236e-04, 1.9591e-04, 2.0048e-04,\n",
            "        6.7780e-05, 1.3583e-04, 9.0127e-05, 7.8274e-05, 1.1171e-04, 1.9848e-04,\n",
            "        2.1890e-04, 5.5572e-05, 6.0271e-05, 6.3246e-05, 5.6009e-05, 1.4475e-04,\n",
            "        9.1070e-05, 1.5075e-04, 8.4249e-05, 2.5272e-04, 1.6146e-04, 2.0761e-04,\n",
            "        2.2771e-04, 1.0878e-04, 2.5597e-04, 2.3357e-04, 1.4120e-04, 6.6141e-05,\n",
            "        1.4840e-04, 1.4152e-04, 2.0078e-04, 1.3118e-04, 2.1293e-04, 1.3930e-04,\n",
            "        1.6474e-04, 1.5029e-04, 1.7232e-04, 1.4935e-04, 1.2804e-04, 1.0026e-04,\n",
            "        9.5631e-05, 1.6909e-04, 1.4045e-04, 1.1528e-04, 8.5934e-05, 8.6531e-05,\n",
            "        1.5294e-04, 1.3891e-04, 5.1189e-05, 1.5053e-04, 1.1579e-04, 1.1117e-04,\n",
            "        2.1040e-04, 1.2088e-04, 1.3951e-04, 9.0226e-05, 1.3969e-04, 4.3354e-04,\n",
            "        2.4637e-04, 1.5337e-04, 8.9476e-05, 9.2602e-05, 9.4919e-05, 1.3867e-04,\n",
            "        8.5736e-05, 1.2260e-04, 1.3567e-04, 7.8328e-05, 1.4308e-04, 1.0708e-04,\n",
            "        8.6747e-05, 7.9725e-05, 9.7493e-05, 4.7718e-05, 4.9209e-05, 7.6372e-05,\n",
            "        1.0924e-04, 5.1297e-05, 6.9902e-05, 1.3259e-04], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform probabilities into actual labels"
      ],
      "metadata": {
        "id": "JaJw6SJWs_T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]\n",
        "# Show top categories per image\n",
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tARnZNfOs-me",
        "outputId": "5a559af6-1a0f-4c4e-a4e7-f52bfd60afaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-22 09:10:34--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-22 09:10:35 (103 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n",
            "Samoyed 0.8236806392669678\n",
            "Arctic fox 0.01424469519406557\n",
            "white wolf 0.012371598742902279\n",
            "Pomeranian 0.007867556065320969\n",
            "keeshond 0.006377127952873707\n"
          ]
        }
      ]
    }
  ]
}